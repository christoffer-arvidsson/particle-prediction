#+auto_tangle: t
#+EXPORT_FILE_NAME: train_lstm
* Transformer
:PROPERTIES:
:header-args: :exports both :session video-frame-transformer :eval no-export :results raw :async yes :tangle train_lstm.py
:END:
** Libraries
#+begin_src jupyter-python :results silent
from models import ParticlePredictorLSTM, ConvolutionalAutoencoder
from data import create_sequence_generator
from callbacks import LogImageSequenceCallback
import tensorflow as tf
import tensorflow.keras as keras

import numpy as np

import datetime
import matplotlib.pyplot as plt
#+end_src

** Parameters
#+begin_src jupyter-python :results silent
lr = 1e-2
steps_per_epoch = 20
image_size = 64
batch_size = 16
prior_len = 8
truth_len = 1
code_dim = 64
video_dataset = create_sequence_generator(image_size, batch_size, prior_len, truth_len)
#+end_src


** Train
#+begin_src jupyter-python
autoencoder = keras.models.load_model(
    f"trained_models/autoencoder_dim_{code_dim}/model/",
)
autoencoder.trainable = False
video_dataset = create_sequence_generator(image_size, batch_size, prior_len, truth_len)

log_dir = f'logs/lstm_{code_dim}_{datetime.datetime.now().strftime("%Y%m%d-%H%M%S")}'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq='batch')

x, y = next(video_dataset)
prior = tf.convert_to_tensor(x[0])
truth = tf.convert_to_tensor(y[0])
image_callback = LogImageSequenceCallback(log_dir, prior, truth)

model = ParticlePredictorLSTM(autoencoder, code_dim, prior_len, truth_len, filt_dim=code_dim+2)
model.build(input_shape=(None, prior_len, code_dim))
optimizer = keras.optimizers.Adam(learning_rate=lr)
model.compile(optimizer=optimizer, loss=keras.losses.MeanSquaredError(), run_eagerly=False)

model.fit(
    video_dataset,
    epochs=50,
    steps_per_epoch=steps_per_epoch,
    callbacks=[
        image_callback,
        tensorboard_callback,
    ]
)

model.save(f'trained_models/lstm_predictor')
#+end_src

#+RESULTS:
:RESULTS:
: Epoch 1/20
# [goto error]
#+begin_example

ValueErrorTraceback (most recent call last)
<ipython-input-3-d83fd6684c03> in <module>
     18 model.compile(optimizer=optimizer, loss=keras.losses.MeanSquaredError(), run_eagerly=True)
     19
---> 20 model.fit(
     21     video_dataset,
     22     epochs=20,

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1098                 _r=1):
   1099               callbacks.on_train_batch_begin(step)
-> 1100               tmp_logs = self.train_function(iterator)
   1101               if data_handler.should_sync:
   1102                 context.async_wait()

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in train_function(iterator)
    803       def train_function(iterator):
    804         """Runs a training execution with one step."""
--> 805         return step_function(self, iterator)
    806
    807     else:

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in step_function(model, iterator)
    793
    794       data = next(iterator)
--> 795       outputs = model.distribute_strategy.run(run_step, args=(data,))
    796       outputs = reduce_per_replica(
    797           outputs, self.distribute_strategy, reduction='first')

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py in run(***failed resolving arguments***)
   1257       fn = autograph.tf_convert(
   1258           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)
-> 1259       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
   1260
   1261   def reduce(self, reduce_op, value, axis):

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
   2728       kwargs = {}
   2729     with self._container_strategy().scope():
-> 2730       return self._call_for_each_replica(fn, args, kwargs)
   2731
   2732   def _call_for_each_replica(self, fn, args, kwargs):

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
   3415   def _call_for_each_replica(self, fn, args, kwargs):
   3416     with ReplicaContext(self._container_strategy(), replica_id_in_sync_group=0):
-> 3417       return fn(*args, **kwargs)
   3418
   3419   def _reduce_to(self, reduce_op, value, destinations, options):

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    570   def wrapper(*args, **kwargs):
    571     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.UNSPECIFIED):
--> 572       return func(*args, **kwargs)
    573
    574   if inspect.isfunction(func) or inspect.ismethod(func):

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in run_step(data)
    786
    787       def run_step(data):
--> 788         outputs = model.train_step(data)
    789         # Ensure counter is updated only if `train_step` succeeds.
    790         with ops.control_dependencies(_minimum_control_deps(outputs)):

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--> 828       result = self._call(*args, **kwds)
    829       compiler = "xla" if self._experimental_compile else "nonXla"
    830       new_tracing_count = self.experimental_get_tracing_count()

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    869       # This is the first call of __call__, so we have to initialize.
    870       initializers = []
--> 871       self._initialize(args, kwds, add_initializers_to=initializers)
    872     finally:
    873       # At this point we know that the initialization is complete (or less

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    723     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    724     self._concrete_stateful_fn = (
--> 725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    726             *args, **kwds))
    727

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2967       args, kwargs = None, None
   2968     with self._lock:
-> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)
   2970     return graph_function
   2971

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3359
   3360           self._function_cache.missed.add(call_context_key)
-> 3361           graph_function = self._create_graph_function(args, kwargs)
   3362           self._function_cache.primary[cache_key] = graph_function
   3363

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3194     arg_names = base_arg_names + missing_arg_names
   3195     graph_function = ConcreteFunction(
-> 3196         func_graph_module.func_graph_from_py_func(
   3197             self._name,
   3198             self._python_function,

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    988         _, original_func = tf_decorator.unwrap(python_func)
    989
--> 990       func_outputs = python_func(*func_args, **func_kwargs)
    991
    992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    632             xla_context.Exit()
    633         else:
--> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
    635         return out
    636

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/eager/function.py in bound_method_wrapper(*args, **kwargs)
   3885     # However, the replacer is still responsible for attaching self properly.
   3886     # TODO(mdan): Is it possible to do it here instead?
-> 3887     return wrapped_fn(*args, **kwargs)
   3888   weak_bound_method_wrapper = weakref.ref(bound_method_wrapper)
   3889

~/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    975           except Exception as e:  # pylint:disable=broad-except
    976             if hasattr(e, "ag_error_metadata"):
--> 977               raise e.ag_error_metadata.to_exception(e)
    978             else:
    979               raise

ValueError: in user code:

    /home/eethern/Projects/course/master/course/advml/homework/frame_prediction/models.py:249 train_step  *
        loss = self.compiled_loss(encoded_y, y_pred, regularization_losses=self.losses)
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__  **
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__
        losses = call_fn(y_true, y_pred)
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1198 mean_squared_error
        return K.mean(math_ops.squared_difference(y_pred, y_true), axis=-1)
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10250 squared_difference
        _, _, _op, _outputs = _op_def_library._apply_op_helper(
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper
        op = g._create_op_internal(op_type_name, inputs, dtypes=None,
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal
        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal
        ret = Operation(
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2015 __init__
        self._c_op = _create_c_op(self._graph, node_def, inputs,
    /home/eethern/.pyenv/versions/ml/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op
        raise ValueError(str(e))

    ValueError: Dimensions must be equal, but are 144 and 32 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](particle_predictor/StatefulPartitionedCall, strided_slice)' with input shapes: [32,144,16], [32,16].
#+end_example
:END:
