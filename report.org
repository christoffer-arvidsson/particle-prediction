#+TITLE: Advanced machine learning - Homework A
#+SUBTITLE: Graph Neural Networks
#+SETUPFILE: ~/Dropbox/org/org-roam/setup_file.org
#+EXPORT_FILE_NAME: report
#+options: toc:3 num:3

* Introduction
_Task_: Use graph neural networks to perform node and graph classification tasks on two different datasets:
1. Citation dataset (Cora)
2. Quantum bit correction dataset

See the appendix for complete notebooks used.

* Assignment 1: Node classification on the Cora dataset
Cora is a citation network dataset for academic papers. Each paper (node) have a
set of words used in the paper. The complete dictionary has 1433 words and the
feature vector for each node is the presence/absence of a word in the paper.
There are no edge features in this dataset, though edges mark citations between
papers (undirected).

The goal is to classify each node into one of 7 different classes based their
node features as well as the graph structure. Note that only 140 nodes are
actually labelled, making supervised learning inefficient.

** Task 1a)
#+RESULTS: dataset-expl
: Num graphs: 1
: Graph(n_nodes=2708, n_node_features=1433, n_edge_features=None, n_labels=7)
: 	Length train: 140
: 	Length validate: 500
: 	Length test: 1000
: 	x: (2708, 1433)
: 	a: (2708, 2708)
: 	y: (2708, 7)

From this, it is clear the Cora dataset has one graph, where the majority of the
nodes lack labels. This is problematic for supervised learning since there are
likely too few examples to generalise to the remainder of the graph.
Unsupervised learning can leverage the graph structure to infer labels on
unlabelled nodes, which is why it will likely perform better than just
supervised learning.

** Task 1b), 1c), 1d)
Train an MLP (listing [[mlp-model]]) and a Convolutional GNN model (listing
ref:gcn-model) on this dataset. Use early stopping to avoid overfitting (see
section [[sec:a1]]).

#+attr_latex: :width 1.0\textwidth
#+caption: Loss and accuracy of the MLP model over 10 epochs.
#+RESULTS: code:mlp-metrics
[[file:img/mlp-loss.png]]

#+attr_latex: :width 0.5\textwidth
#+caption: Clustering nodes after classyfing one graph using the trained MLP model.
#+RESULTS: mlp-trained-tsne
[[file:img/mlp-trained.png]]

#+name: fig:gcn-metrics
#+attr_latex: :width 1.0\textwidth
#+caption: Loss and accuracy for the GCN model.
#+RESULTS: code:1gcn-metrics
[[file:img/gcn-loss.png]]

#+attr_latex: :width 0.5\textwidth
#+caption: Clustering nodes after classifying one graph using the trained GCN model.
#+RESULTS: gcn-trained-tsne
[[file:img/gcn-trained.png]]

Test accuracy's are roughly 60% for the MLP and 80% for the GNN.

** Task 2)
To improve the model, we can use a attention mechanism to focus on certain
neighbours (listing ref:imp-model). An additional improvement is adding an L2 regularizer.

#+caption: Loss and accuracy for the GAT model.
#+attr_latex: :width 1.0\textwidth
#+RESULTS: code:gat-metrics
[[file:img/gat-metrics.png]]

This model reaches roughly 83% accuracy on the test set, which is a small
improvement over previous models.

#+attr_latex: :width 0.5\textwidth
#+caption: TSNE clustering of the trained GAT model.
#+RESULTS: code:gat-trained-tsne
[[file:img/gat-trained.png]]

* Assignment 2: Graph classification on Qbit dataset
This task has a lot more freedom than the previous one. The goal is to come up
with as good a model as possible for the given dataset.

Given in the description for the dataset, we know that each graph is fully
connected, and that there are four classes used to describe the error. Edge
weights are scalars (Inverse distances on a grid), and each node have a
two-dimensional feature vector.

Divide the dataset into splits of 70/10/20% corresponding to
train/validate/test. The number of graphs in each split is shown below

#+RESULTS: code:2-splits
: Train:  2800
: Validate:  400
: Test:  800

The following describes the model I arrived at after some iterating
1. Use the edge weights in the convolution layers. For scalar weights, do this by multiplying adjacency matrix.
2. Use =GraphConv= instead of =GCNConv=. This removes the row normalization and adds a skip connection, allowing it to reuse its own feature vector.
3. Add batch normalization, which seemed to improve the prediction somewhat.
4. Graph attention layer with multiple attention heads.
5. Reduce by using a global mean pool (graph classification)
6. Finally, classify by a simple dense layer.

The final model is shown in listing [[code:2-model]]. Figure ref:fig:2-metrics
shows the loss and accuracy during training.

#+name: fig:2-metrics
#+RESULTS: code:2metrics
[[file:img/2-loss.png]]

Finally, this model achieves a test accuracy of almost 80%.

* Notebooks
** Dataset 1: Cora dataset
:PROPERTIES:
:header-args: :exports both :session gnn-dataset-1 :eval no-export :results raw :async yes
:END:
<<sec:a1>>
Cora is a citation network dataset for academic papers. Each paper (node) have a
set of words used in the paper. The complete dictionary has 1433 words and the
feature vector for each node is the presence/absence of a word in the paper.
There are no edge features in this dataset, though edges mark citations between
papers (undirected).

The goal is to classify each node into one of 7 different classes based their
node features as well as the graph structure. Note that only 140 nodes are
actually labelled, making supervised learning inefficient.

I used =Tensorflow= along with its graph library =Spektral= for this task.

*** Libraries
#+begin_src jupyter-python :results silent
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
import spektral
from spektral.layers import GCNConv, GATConv, GCSConv, ChebConv
from spektral.data import SingleLoader
from spektral.transforms import AdjToSpTensor, LayerPreprocess

# Visualization
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import matplotlib as mpl

import datetime

plt.style.use('seaborn-whitegrid')
mpl.rcParams.update({
    'text.usetex': True,
    'pgf.rcfonts': False,
    'lines.linewidth': 1,
    'figure.dpi': 300,
})
%config inlinebackend.print_figure_kwargs={'facecolor' : "w"}
#+end_src

Also define a helpful visualization function using t-distributed stochastic
neighbour embedding (TSNE) that we'll use for both datasets
#+begin_src jupyter-python :results silent
def visualize(h, color):
    z = TSNE(n_components=2, perplexity=5).fit_transform(h)
    fig, ax = plt.subplots(1,1)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.scatter(z[:,0], z[:,1], c=color, cmap='Set2')
    return fig, ax
#+end_src

*** Dataset exploration
Get dataset
#+begin_src jupyter-python :results silent
cora = spektral.datasets.citation.Citation(
    'cora',
    normalize_x=True,
    transforms=[
        AdjToSpTensor()
    ])
#+end_src

Explore and load dataset. =Spektral= has the dataset built in.
#+name: dataset-expl
#+begin_src jupyter-python :results raw drawer
n_node_features = cora[0].n_node_features
n_edge_features = cora[0].n_edge_features
n_labels = cora[0].n_labels
mask_tr, mask_va, mask_te = cora.mask_tr, cora.mask_va, cora.mask_te
graph = cora[0]
x, a, y = graph.x, graph.a, graph.y
real_classes = np.argmax(y, axis=1) # one-hot encoding -> integer

print(f'Num graphs: {len(cora)}')
print(f'{cora[0]}')
print(f'\tLength train: {mask_tr.sum()}')
print(f'\tLength validate: {mask_va.sum()}')
print(f'\tLength test: {mask_te.sum()}')
print('\tx:', x.shape)
print('\ta:', a.shape)
print('\ty:', y.shape)
#+end_src

*** Supervised learning with a MLP
First attempt to use supervised learning on the small training dataset.
Construct an MLP using =Keras= subclassing. It's a simple two-layer perceptron
with a softmax activation function for classification.

Define some parameters used in the model and for training
#+name: mlp-params
#+begin_src jupyter-python :results silent
hidden_layers = 16
patience = 5 # epochs with no improvement
lr = 1e-2
num_epochs = 100
batch_size = 16
#+end_src

Define the model
#+name: mlp-model
#+caption: MLP model definition.
#+begin_src jupyter-python :results silent
class MLP(Model):
    def __init__(self, n_hidden, n_classes):
        super(MLP, self).__init__()
        self.dense = Dense(n_node_features, activation='relu')
        self.dropout = Dropout(0.5)
        self.classifier = Dense(n_classes, activation='softmax')

    def call(self, inputs, training=False):
        out = self.dense(inputs)
        if training:
            out = self.dropout(out, training=training)
        return self.classifier(out)
#+end_src

Use cross-entropy for the loss function. Train it with the =EarlyStopping=
callback, each epoch tests against the validation split. When patience is exceeded, restore the best performing model (on the validation split).
#+name: mlp-train
#+begin_src jupyter-python
loss_fn = CategoricalCrossentropy()
optimizer = Adam(learning_rate=lr)
model = MLP(hidden_layers, n_labels)

model.compile(optimizer=optimizer, loss=loss_fn, metrics=['acc'])
history = model.fit(
    x[mask_tr],
    y[mask_tr],
    batch_size=batch_size,
    epochs=num_epochs,
    validation_data=(x[mask_va], y[mask_va]),
    verbose=2,
    callbacks=[EarlyStopping(
        monitor='val_loss',
        mode='min',
        patience=patience,
        restore_best_weights=True,
    )]
)

model.save(f'trained_models/mlp')
#+end_src

Figure ref:fig:mlp-metrics shows the loss and accuracy during training of the
MLP.

#+name: code:mlp-metrics
#+begin_src jupyter-python :file img/mlp-loss.png :exports results
fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,3))
ax1.plot(history.history['loss'], label='training loss')
ax1.plot(history.history['val_loss'], label='validation loss')
ax1.set_xlabel('epoch')
ax1.set_ylabel('loss')
ax1.set_title('Model loss')
ax1.legend()
ax2.plot(history.history['acc'], label='training accuracy')
ax2.plot(history.history['val_acc'], label='validation accuracy')
ax2.set_xlabel('epoch')
ax2.set_ylabel('accuracy')
ax2.set_title('Model accuracy')
ax2.legend()
fig.tight_layout()
#+end_src

Finally, run the model on the test split

#+name: mlp-test
#+begin_src jupyter-python
model.evaluate(x[mask_te], y[mask_te], verbose=2)
#+end_src

#+RESULTS: mlp-test
: 32/32 - 0s - loss: 1.2662 - acc: 0.5920

Due to stochasticity, the accuracy is somewhere around 58-60%, which is not
amazing. Visualize the results using TSNE

#+name:mlp-trained-tsne
#+begin_src jupyter-python :file img/mlp-trained.png
out = model.call(x)
fig, ax = visualize(out, real_classes)
plt.show()
#+end_src

*** Semi-supervised learning using Graph convolutions
Idea is to use the information in the graph structure to aid classifying nodes.
If we assume nodes that are connected are related in such a way that they have a
higher probability of having the same class, then we can use a nodes neighbors
to help classify it. The mechanism for this is to use graph convolutions, which
by message-passing gathers information from neighbor features vectors reduces
that information to a single vector. This information is then hopefully a better
latent vector than just looking at the single node feature vector as was done
earlier.

First define some parameters
#+name: gcn-params
#+begin_src jupyter-python :results silent
hidden_layers = 32
patience = 10 # epochs with no improvement
lr = 1e-2
num_epochs = 200
loss_fn = CategoricalCrossentropy(reduction='sum')
optimizer = Adam(learning_rate=lr)
#+end_src

Next define the model using subclassing
#+name: gcn-model
#+caption: GCN model definition.
#+begin_src jupyter-python :results silent
class GCN(Model):
    def __init__(self, n_hidden, n_labels):
        super(GCN, self).__init__()
        self.dropout = Dropout(0.5)
        self.gcn0 = GCNConv(channels=n_hidden, activation='relu')
        self.classification = GCNConv(n_labels, activation='softmax')

    def call(self, inputs):
        x, a = inputs
        x = self.dropout(x)
        x = self.gcn0([x,a])
        return self.classification([x,a])

#+end_src

Load the data, =spektral.data.SingleLoader= loads all nodes from a dataset with a
single graph. Here it becomes slightly problematic since our dataset has one
graph. In order to properly use this, we need to use sampling weights such that
we only sample nodes (and subsequently edges) from the correct split. Hence, we
convert the binary masks to sampling weights that =Keras= can understand.

Reload the dataset and apply transform for =GCNConv=
#+begin_src jupyter-python :results silent
cora = spektral.datasets.citation.Citation(
    'cora',
    normalize_x=True,
    transforms=[
        LayerPreprocess(GCNConv),
        AdjToSpTensor()
    ])
#+end_src

#+name: gcn-load-data
#+begin_src jupyter-python :results none
# Equally weight samples in each split
def mask_to_weights(mask):
    return mask.astype(np.float32) / np.count_nonzero(mask)

weights_tr, weights_va, weights_te = [
    mask_to_weights(mask) for mask in [mask_tr, mask_va, mask_te]
]

loader_tr = SingleLoader(cora, sample_weights=weights_tr)
loader_va = SingleLoader(cora, sample_weights=weights_va)
loader_te = SingleLoader(cora, sample_weights=weights_te)
#+end_src

One interesting side effect of GCNs is that they work decently even without any training, due to them just using the graph structure. Try running the model without training and visualize the clusters by using

#+name: gcn-compile
#+begin_src jupyter-python :file img/gcn-untrained.png
model = GCN(hidden_layers, n_labels)
model.compile(optimizer, loss_fn, weighted_metrics=['acc'])
#+end_src

#+RESULTS: gcn-compile

Now train the network. Again, use early stopping to not overfit the model

#+name: gcn-train
#+begin_src jupyter-python :results output :exports code
history = model.fit(
    loader_tr.load(),
    steps_per_epoch=loader_tr.steps_per_epoch,
    epochs=num_epochs,
    validation_data=loader_va.load(),
    validation_steps=loader_va.steps_per_epoch,
    verbose=2,
    callbacks=[EarlyStopping(
        monitor='val_loss',
        mode='min',
        patience=patience,
        restore_best_weights=True
    )]
)

model.save(f'trained_models/gcn')
#+end_src

Figure ref:fig:gcn-metrics shows the loss and accuracy during training.

#+name: code:1gcn-metrics
#+begin_src jupyter-python :file img/gcn-loss.png :exports results
fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,3))
ax1.plot(history.history['loss'], label='training loss')
ax1.plot(history.history['val_loss'], label='validation loss')
ax1.set_xlabel('epoch')
ax1.set_ylabel('loss')
ax1.set_title('Model loss')
ax1.legend()
ax2.plot(history.history['acc'], label='training accuracy')
ax2.plot(history.history['val_acc'], label='validation accuracy')
ax2.set_xlabel('epoch')
ax2.set_ylabel('accuracy')
ax2.set_title('Model accuracy')
ax2.legend()
fig.tight_layout()
plt.show()
#+end_src

Test the model on the test split
#+begin_src jupyter-python
out = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)
out
#+end_src

#+RESULTS:
: 1/1 [==============================] - 0s 18ms/step - loss: 0.6633 - acc: 0.8060

Much better in comparison to the MLP model earlier. Next visualize it using TSNE

#+name:gcn-trained-tsne
#+begin_src jupyter-python :file img/gcn-trained.png
out = model.call([x, a])
fig, ax = visualize(out, real_classes)
plt.show()
#+end_src

*** Improved model using attention
We can use attention mechanisms in our convolution layers to further improve the prediction. Parameters for this model

Reload the dataset and apply transform for =GATConv=
#+begin_src jupyter-python :results silent
cora = spektral.datasets.citation.Citation(
    'cora',
    normalize_x=True,
    transforms=[
        LayerPreprocess(GATConv),
        AdjToSpTensor()
    ])

loader_tr = SingleLoader(cora, sample_weights=weights_tr)
loader_va = SingleLoader(cora, sample_weights=weights_va)
loader_te = SingleLoader(cora, sample_weights=weights_te)
#+end_src

Parameters used for this model. Add an =L2= regularizer to avoid overfitting
#+name: imp-params
#+begin_src jupyter-python :results silent
hidden_layers = 8
n_attn_heads = 8
patience = 100 # epochs with no improvement
lr = 5e-3
l2_reg = 2.5e-4
num_epochs = 1000
loss_fn = CategoricalCrossentropy(reduction='sum')
optimizer = Adam(learning_rate=lr)
#+end_src

Model definition
#+name: imp-model
#+caption: Attention model definition.
#+begin_src jupyter-python :results silent

class GCN_improved(Model):
    def __init__(self, n_hidden, n_labels):
        super(GCN_improved, self).__init__()
        self.do1 = Dropout(0.6)
        self.gat0 = GATConv(
            channels=n_hidden,
            attn_heads=n_attn_heads,
            concat_heads=True,
            dropout_rate=0.6,
            activation='elu',
            kernel_regularizer=l2(l2_reg),
            attn_kernel_regularizer=l2(l2_reg),
            bias_regularizer=l2(l2_reg),
        )
        self.do2 = Dropout(0.6)
        self.classification = GATConv(
            channels=n_labels,
            attn_heads=1,
            concat_heads=False,
            dropout_rate=0.6,
            activation='softmax',
            kernel_regularizer=l2(l2_reg),
            attn_kernel_regularizer=l2(l2_reg),
            bias_regularizer=l2(l2_reg),
        )

    def call(self, inputs):
        x, a = inputs
        x = self.do1(x)
        x = self.gat0([x,a])
        x = self.do2(x)
        return self.classification([x,a])

#+end_src

Compilation and training
#+name: imp-compile
#+begin_src jupyter-python
model = GCN_improved(hidden_layers, n_labels)
model.compile(optimizer, loss_fn, weighted_metrics=['acc'])

name = 'improved+reg'
log_dir = f'log/cora/{name}_{datetime.datetime.now().strftime("%Y%m%d-%H%M%S")}'
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, update_freq='batch')

history = model.fit(
    loader_tr.load(),
    steps_per_epoch=loader_tr.steps_per_epoch,
    epochs=num_epochs,
    validation_data=loader_va.load(),
    validation_steps=loader_va.steps_per_epoch,
    verbose=2,
    shuffle=False,
    callbacks=[
        tensorboard_callback,
        EarlyStopping(
            monitor='val_loss',
            mode='min',
            patience=patience,
            restore_best_weights=True
        )
    ]
)
model.save('trained_models/improved')
#+end_src

Figure ref:code:1gat-metrics shows the loss and accuracy during training of the
improved model using =GATConv= layers.

#+name: code:gat-metrics
#+begin_src jupyter-python :exports results :file img/gat-metrics.png
fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,3))
ax1.plot(history.history['loss'], label='training loss')
ax1.plot(history.history['val_loss'], label='validation loss')
ax1.set_xlabel('epoch')
ax1.set_ylabel('loss')
ax1.set_title('Model loss')
ax1.legend()
ax2.plot(history.history['acc'], label='training accuracy')
ax2.plot(history.history['val_acc'], label='validation accuracy')
ax2.set_xlabel('epoch')
ax2.set_ylabel('accuracy')
ax2.set_title('Model accuracy')
ax2.legend()
fig.tight_layout()
plt.show()
#+end_src

Test the model on the test split
#+begin_src jupyter-python
loader_te = SingleLoader(cora, sample_weights=weights_te) # Loads one graph
out = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)
out
#+end_src

#+RESULTS:
: 1/1 [==============================] - 0s 74ms/step - loss: 0.9821 - acc: 0.8440

Next visualize using TSNE

#+name: code:gat-trained-tsne
#+begin_src jupyter-python :file img/gat-trained.png
out = model.call([x,a])
fig, ax = visualize(out, real_classes)
plt.show()
#+end_src

** Dataset 2: Quantum bit error correction dataset
:PROPERTIES:
:header-args: :exports both :session gnn-dataset-2-torch
:END:
This task has a lot more freedom than the previous one. The goal is to come up
with as good a model as possible for the given dataset.

*** Libraries
For this task, I just decided to use =Pytorch= and =Pytorch-geometric= since
converting the dataset to spektral would just complicate things. Code-wise, it
is practically the same since =Tensorflow= and =Pytorch= have grown fairly close to
eachother anyway. Import some libraries

#+begin_src jupyter-python :results silent
import numpy as np

import torch
import torch_geometric
from torch.nn import Linear, LogSoftmax, Softmax, Sequential, Dropout
import torch.nn.functional as F
import torch.nn as nn
from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, BatchNorm, GraphConv
from torch_geometric.data import DataLoader

# Visualization
import time
from datetime import datetime
from tensorboardX import SummaryWriter
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import matplotlib as mpl

plt.style.use('seaborn-whitegrid')
mpl.rcParams.update({
    'text.usetex': True,
    'pgf.rcfonts': False,
    'lines.linewidth': 1,
    'figure.dpi': 300,
})
%config inlinebackend.print_figure_kwargs={'facecolor' : "w"}
#+end_src

*** Parameters
Define some parameters we'll use in both the model and for training
#+begin_src jupyter-python :results silent
batch_size = 256
hidden_channels = 64
att_heads = 8
l2_reg = 2.5e-4
num_epochs = 1000
patience = 10 # Num epochs with no improvement
lr = 1e-3
#+end_src

*** Dataset
The dataset is given in a =.pt= file, which we conveniently can load directly into
=Pytorch-geometric= via a similar strategy to the =SingleLoader= class in =spektral=.
Note that this dataset have many graphs, so we here load batches of graphs.

This dataset is not split yet, so we can create our own 70/10/20% splits for train/validation/test.

#+name: code:2-splits
#+begin_src jupyter-python
dataset = torch.load("graphs.pt", map_location=torch.device('cpu'))
np.random.shuffle(dataset)
first_ind = int(len(dataset) * 0.7)
second_ind = int(len(dataset) * 0.8)
train_split, val_split, test_split = dataset[:first_ind], dataset[first_ind:second_ind], dataset[second_ind:]
train_loader = DataLoader(train_split, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_split, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_split, batch_size=batch_size, shuffle=True)

print("Train: ", len(train_split))
print("Validate: ", len(val_split))
print("Test: ", len(test_split))
#+end_src

Given in the description for the dataset, we know that each graph is fully
connected, and that there are four classes used to describe the error. Edge
weights are scalars (Inverse distances on a grid), and each node have a
two-dimensional feature vector.

*** Model definition
The following describes the model I arrived at after some iterating
1. Use the edge weights in the convolution layers. For scalar weights, do this by multiplying adjacency matrix.
2. Use =GraphConv= instead of =GCNConv=. This removes the row normalization and adds a skip connection, allowing it to reuse its own feature vector.
3. Add batch normalization, which seemed to do improve the preiction a tiny bit.
4. Graph attention layer with multiple attention heads.
5. Reduce by using a global mean pool (graph classification)
6. Finally, classify by a simple dense layer.

#+name: code:2-model
#+caption: QBit model definition.
#+begin_src jupyter-python :results silent
class GCN(torch.nn.Module):
    def __init__(self, hidden_channels, num_node_features, num_edge_features, num_classes, attn_heads=8):
        super(GCN, self).__init__()
        self.conv1 = GraphConv(num_node_features, hidden_channels)
        self.bnorm1 = BatchNorm(hidden_channels)
        self.conv2 = GraphConv(hidden_channels, hidden_channels)
        self.bnorm2 = BatchNorm(hidden_channels)
        self.gat1 = GATConv(hidden_channels, hidden_channels, heads=attn_heads, concat=True)
        self.mlp = Linear(hidden_channels*att_heads, num_classes)

    def forward(self, x, edge_index, edge_attr, batch):
        # Node embeddings
        out = F.relu(self.conv1(x, edge_index, edge_weight=edge_attr))
        out = self.bnorm1(out)
        out = F.relu(self.conv2(out, edge_index, edge_weight=edge_attr))
        out = self.bnorm2(out)
        out = F.relu(self.gat1(out, edge_index))

        # Pool
        out = global_mean_pool(out, batch)

        # Classification
        out = self.mlp(out)
        out = F.log_softmax(out, dim=1)
        return out
#+end_src

Create the model

#+begin_src jupyter-python
model = GCN(
    num_node_features=2,
    hidden_channels=hidden_channels,
    num_edge_features=1,
    num_classes=4,
    attn_heads=att_heads,
).double().to('cpu')
#+end_src

#+RESULTS:

*** Training
Use Kullback-Leibler divergence loss since the dataset comes with probability
distributions of the four classes. Testing and validation is still done on
discrete classes (argmax). I also use =Tensorboard= to log my results a bit more
efficiently. Finally, the early-stopping mechanism is implemented manually,
rather than through a callback.

#+begin_src jupyter-python :results silent
name = 'final64_lr-3'
optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=l2_reg)
criterion = torch.nn.KLDivLoss(reduction='batchmean')
writer = SummaryWriter("./log/qbit/" + name + '_' + datetime.now().strftime("%Y%m%d-%H%M%S"))

def train(loader, writer):
    model.train()

    total_loss = 0
    for data in loader:  # Iterate in batches over the training dataset.
        out = model(data.x, data.edge_index, data.edge_attr, data.batch)  # Perform a single forward pass.
        target = data.y
        loss = criterion(out, target)  # Compute the loss.
        loss.backward()  # Derive gradients.
        optimizer.step()  # Update parameters based on gradients.
        total_loss += loss.item() * data.num_graphs
        optimizer.zero_grad()  # Clear gradients
    total_loss /= len(loader.dataset)
    return total_loss

@torch.no_grad()
def test(loader):
    correct = 0
    total_loss = 0
    for data in loader:  # Iterate in batches over the training/test dataset.
        out = model(data.x, data.edge_index, data.edge_attr, data.batch)
        pred = out.argmax(dim=1)  # Use the class with highest probability.
        target = data.y.argmax(dim=1)

        correct += int((pred == target).sum())

    return correct / len(loader.dataset)# Derive ratio of correct predictions
#+end_src

Torch doesn't seem to have a simple EarlyStopping mechanism, so I made one
myself. It supports minimum delta, checkpointing and min/max metrics.

#+begin_src jupyter-python
class EarlyStopping:
    def __init__(self, patience=10, delta=0, active=True,
                 save_checkpoint=False, path='ckpt.pt', mode='min',
                 verbose=False):
        self.patience = patience
        self.delta = delta
        self.counter = 0
        self.active = active
        self.best_val = None
        self.save_checkpoint = save_checkpoint
        self.verbose = verbose
        self.path=path
        self.early_stop = False

        if mode not in ['min', 'max']:
            print("EarlyCallback: Could not read mode, defaulting to min.")
            self.mode = 'min'
        if mode == 'min':
            self.mode_op = np.less
        elif mode == 'max':
            self.mode_op = np.greater
            self.delta *= -1

    def __call__(self, value, model):
        if self.active:
            if self.best_val is None:
                self.best_val = value
                self.save(value, model)
            elif self.mode_op(value + self.delta, self.best_val):
                self.best_val = value
                self.save(value, model)
                self.counter = 0
            else:
                self.counter += 1
                if self.counter > patience:
                    self.early_stop = True

    def save(self, value, model):
        if self.save_checkpoint:
            if self.verbose:
                print("Validation loss changed from {self.min_val} to {value}, saving model.")

            torch.save(model.state_dict(), self.path)


#+end_src

#+RESULTS:

Finally train and test the model.

#+begin_src jupyter-python
early_stop = EarlyStopping(patience, mode='max', path='ckpts/es_ckpt.pt', save_checkpoint=True)
epochs = []
tr_loss = []
va_acc = []
print("Begin training...")
for epoch in range(1, num_epochs + 1):
    # Train
    total_loss = train(train_loader, writer)

    # Early stopping
    curr_val_acc = test(val_loader)
    early_stop(curr_val_acc, model)
    if early_stop.early_stop:
        print("Patience exceeded.")
        break

    # Logging
    train_acc = test(train_loader)
    epochs.append(epoch)
    tr_loss.append(total_loss)
    va_acc.append(curr_val_acc)

    writer.add_scalar("train/loss", total_loss, epoch)
    writer.add_scalar("train/train accuracy", train_acc, epoch)
    writer.add_scalar("train/validation accuracy", curr_val_acc, epoch)

    if epoch % 5 == 0:
        print(f' Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Val Acc: {curr_val_acc:.4f}')

print("End training.")
#+end_src

#+RESULTS:
: Begin training...
:  Epoch: 005, Train Acc: 0.7054, Val Acc: 0.6600
:  Epoch: 010, Train Acc: 0.7864, Val Acc: 0.7125
:  Epoch: 015, Train Acc: 0.8214, Val Acc: 0.7475
:  Epoch: 020, Train Acc: 0.8429, Val Acc: 0.7350
:  Epoch: 025, Train Acc: 0.8550, Val Acc: 0.7100
: Patience exceeded.
: End training.

#+begin_src jupyter-python
# model.load_state_dict(torch.load("es_ckpt.pt"))
torch.save(model.state_dict, 'trained_models/qbit.pt')
test_acc = test(test_loader)
print("Test_acc:", test_acc)
#+end_src

#+RESULTS:
: Test_acc: 0.80375

#+name: code:2metrics
#+begin_src jupyter-python :file img/2-loss.png
fig, (ax1,ax2) = plt.subplots(1,2, figsize=(8,3))
ax1.plot(epochs, tr_loss, label='training loss')
ax1.set_xlabel('epoch')
ax1.set_ylabel('loss')
ax1.set_title('Model loss')
ax1.legend()
ax2.plot(epochs, va_acc, label='validation accuracy')
ax2.set_xlabel('epoch')
ax2.set_ylabel('accuracy')
ax2.set_title('Model accuracy')
ax2.legend()
fig.tight_layout()
plt.show()
#+end_src

#+latex: \newpage
** Logs :noexport:
Log from training the MLP

#+RESULTS: mlp-train
#+begin_example
Epoch 1/100
9/9 - 1s - loss: 1.9453 - acc: 0.1500 - val_loss: 1.8854 - val_acc: 0.4020
Epoch 2/100
9/9 - 0s - loss: 1.6457 - acc: 0.7571 - val_loss: 1.7189 - val_acc: 0.5120
Epoch 3/100
9/9 - 0s - loss: 1.0104 - acc: 0.9214 - val_loss: 1.4942 - val_acc: 0.5340
Epoch 4/100
9/9 - 0s - loss: 0.3931 - acc: 0.9857 - val_loss: 1.2839 - val_acc: 0.5840
Epoch 5/100
9/9 - 0s - loss: 0.0914 - acc: 1.0000 - val_loss: 1.3832 - val_acc: 0.5060
Epoch 6/100
9/9 - 0s - loss: 0.0266 - acc: 1.0000 - val_loss: 1.3419 - val_acc: 0.5500
Epoch 7/100
9/9 - 0s - loss: 0.0096 - acc: 1.0000 - val_loss: 1.2993 - val_acc: 0.5840
Epoch 8/100
9/9 - 0s - loss: 0.0055 - acc: 1.0000 - val_loss: 1.2907 - val_acc: 0.6080
Epoch 9/100
9/9 - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 1.3117 - val_acc: 0.6180
INFO:tensorflow:Assets written to: trained_models/mlp/assets
INFO:tensorflow:Assets written to: trained_models/mlp/assets
#+end_example

Log from training the GCN

#+RESULTS: gcn-train
#+begin_example
Epoch 1/200
1/1 - 1s - loss: 1.9461 - acc: 0.2357 - val_loss: 1.9398 - val_acc: 0.4080
Epoch 2/200
1/1 - 0s - loss: 1.9376 - acc: 0.3786 - val_loss: 1.9371 - val_acc: 0.4860
Epoch 3/200
1/1 - 0s - loss: 1.9271 - acc: 0.6357 - val_loss: 1.9316 - val_acc: 0.4440
Epoch 4/200
1/1 - 0s - loss: 1.9143 - acc: 0.7000 - val_loss: 1.9246 - val_acc: 0.4340
Epoch 5/200
1/1 - 0s - loss: 1.8970 - acc: 0.7143 - val_loss: 1.9167 - val_acc: 0.4540
Epoch 6/200
1/1 - 0s - loss: 1.8779 - acc: 0.7429 - val_loss: 1.9089 - val_acc: 0.4680
Epoch 7/200
1/1 - 0s - loss: 1.8596 - acc: 0.7500 - val_loss: 1.9006 - val_acc: 0.4760
Epoch 8/200
1/1 - 0s - loss: 1.8439 - acc: 0.7571 - val_loss: 1.8916 - val_acc: 0.4780
Epoch 9/200
1/1 - 0s - loss: 1.8135 - acc: 0.8000 - val_loss: 1.8813 - val_acc: 0.4860
Epoch 10/200
1/1 - 0s - loss: 1.7961 - acc: 0.7929 - val_loss: 1.8693 - val_acc: 0.5080
Epoch 11/200
1/1 - 0s - loss: 1.7667 - acc: 0.7929 - val_loss: 1.8551 - val_acc: 0.5100
Epoch 12/200
1/1 - 0s - loss: 1.7436 - acc: 0.8071 - val_loss: 1.8392 - val_acc: 0.5400
Epoch 13/200
1/1 - 0s - loss: 1.7150 - acc: 0.8143 - val_loss: 1.8218 - val_acc: 0.5660
Epoch 14/200
1/1 - 0s - loss: 1.6869 - acc: 0.8214 - val_loss: 1.8030 - val_acc: 0.5860
Epoch 15/200
1/1 - 0s - loss: 1.6519 - acc: 0.8571 - val_loss: 1.7831 - val_acc: 0.6080
Epoch 16/200
1/1 - 0s - loss: 1.6107 - acc: 0.8643 - val_loss: 1.7629 - val_acc: 0.6180
Epoch 17/200
1/1 - 0s - loss: 1.5883 - acc: 0.8714 - val_loss: 1.7427 - val_acc: 0.6280
Epoch 18/200
1/1 - 0s - loss: 1.5537 - acc: 0.9000 - val_loss: 1.7227 - val_acc: 0.6440
Epoch 19/200
1/1 - 0s - loss: 1.5183 - acc: 0.8929 - val_loss: 1.7025 - val_acc: 0.6520
Epoch 20/200
1/1 - 0s - loss: 1.4913 - acc: 0.9143 - val_loss: 1.6822 - val_acc: 0.6640
Epoch 21/200
1/1 - 0s - loss: 1.4445 - acc: 0.9214 - val_loss: 1.6618 - val_acc: 0.6800
Epoch 22/200
1/1 - 0s - loss: 1.3892 - acc: 0.9357 - val_loss: 1.6409 - val_acc: 0.6840
Epoch 23/200
1/1 - 0s - loss: 1.3646 - acc: 0.9286 - val_loss: 1.6191 - val_acc: 0.6880
Epoch 24/200
1/1 - 0s - loss: 1.3003 - acc: 0.9429 - val_loss: 1.5968 - val_acc: 0.6980
Epoch 25/200
1/1 - 0s - loss: 1.2758 - acc: 0.9429 - val_loss: 1.5739 - val_acc: 0.7040
Epoch 26/200
1/1 - 0s - loss: 1.2257 - acc: 0.9357 - val_loss: 1.5495 - val_acc: 0.7080
Epoch 27/200
1/1 - 0s - loss: 1.1900 - acc: 0.9643 - val_loss: 1.5238 - val_acc: 0.7220
Epoch 28/200
1/1 - 0s - loss: 1.1410 - acc: 0.9286 - val_loss: 1.4972 - val_acc: 0.7280
Epoch 29/200
1/1 - 0s - loss: 1.1005 - acc: 0.9357 - val_loss: 1.4681 - val_acc: 0.7300
Epoch 30/200
1/1 - 0s - loss: 1.0506 - acc: 0.9500 - val_loss: 1.4392 - val_acc: 0.7360
Epoch 31/200
1/1 - 0s - loss: 1.0315 - acc: 0.9714 - val_loss: 1.4098 - val_acc: 0.7380
Epoch 32/200
1/1 - 0s - loss: 0.9684 - acc: 0.9357 - val_loss: 1.3799 - val_acc: 0.7440
Epoch 33/200
1/1 - 0s - loss: 0.9414 - acc: 0.9429 - val_loss: 1.3496 - val_acc: 0.7600
Epoch 34/200
1/1 - 0s - loss: 0.8568 - acc: 0.9786 - val_loss: 1.3203 - val_acc: 0.7620
Epoch 35/200
1/1 - 0s - loss: 0.8561 - acc: 0.9571 - val_loss: 1.2919 - val_acc: 0.7600
Epoch 36/200
1/1 - 0s - loss: 0.8240 - acc: 0.9571 - val_loss: 1.2636 - val_acc: 0.7640
Epoch 37/200
1/1 - 0s - loss: 0.7659 - acc: 0.9571 - val_loss: 1.2370 - val_acc: 0.7700
Epoch 38/200
1/1 - 0s - loss: 0.7229 - acc: 0.9643 - val_loss: 1.2115 - val_acc: 0.7720
Epoch 39/200
1/1 - 0s - loss: 0.6793 - acc: 0.9714 - val_loss: 1.1873 - val_acc: 0.7720
Epoch 40/200
1/1 - 0s - loss: 0.6593 - acc: 0.9571 - val_loss: 1.1649 - val_acc: 0.7720
Epoch 41/200
1/1 - 0s - loss: 0.6238 - acc: 0.9643 - val_loss: 1.1424 - val_acc: 0.7740
Epoch 42/200
1/1 - 0s - loss: 0.5984 - acc: 0.9714 - val_loss: 1.1199 - val_acc: 0.7780
Epoch 43/200
1/1 - 0s - loss: 0.5538 - acc: 0.9714 - val_loss: 1.0959 - val_acc: 0.7820
Epoch 44/200
1/1 - 0s - loss: 0.5654 - acc: 0.9714 - val_loss: 1.0713 - val_acc: 0.7800
Epoch 45/200
1/1 - 0s - loss: 0.5156 - acc: 0.9786 - val_loss: 1.0475 - val_acc: 0.7800
Epoch 46/200
1/1 - 0s - loss: 0.4934 - acc: 0.9786 - val_loss: 1.0246 - val_acc: 0.7820
Epoch 47/200
1/1 - 0s - loss: 0.4639 - acc: 0.9786 - val_loss: 1.0023 - val_acc: 0.7860
Epoch 48/200
1/1 - 0s - loss: 0.4380 - acc: 0.9714 - val_loss: 0.9819 - val_acc: 0.7920
Epoch 49/200
1/1 - 0s - loss: 0.3974 - acc: 0.9929 - val_loss: 0.9625 - val_acc: 0.7940
Epoch 50/200
1/1 - 0s - loss: 0.4074 - acc: 0.9857 - val_loss: 0.9464 - val_acc: 0.7960
Epoch 51/200
1/1 - 0s - loss: 0.3658 - acc: 0.9786 - val_loss: 0.9300 - val_acc: 0.7960
Epoch 52/200
1/1 - 0s - loss: 0.3522 - acc: 0.9786 - val_loss: 0.9136 - val_acc: 0.7960
Epoch 53/200
1/1 - 0s - loss: 0.3486 - acc: 0.9786 - val_loss: 0.8973 - val_acc: 0.7940
Epoch 54/200
1/1 - 0s - loss: 0.3411 - acc: 0.9786 - val_loss: 0.8814 - val_acc: 0.7940
Epoch 55/200
1/1 - 0s - loss: 0.3041 - acc: 0.9786 - val_loss: 0.8687 - val_acc: 0.7920
Epoch 56/200
1/1 - 0s - loss: 0.2929 - acc: 0.9786 - val_loss: 0.8617 - val_acc: 0.7900
Epoch 57/200
1/1 - 0s - loss: 0.2555 - acc: 0.9929 - val_loss: 0.8577 - val_acc: 0.7900
Epoch 58/200
1/1 - 0s - loss: 0.2762 - acc: 0.9786 - val_loss: 0.8558 - val_acc: 0.7780
Epoch 59/200
1/1 - 0s - loss: 0.2433 - acc: 0.9929 - val_loss: 0.8519 - val_acc: 0.7800
Epoch 60/200
1/1 - 0s - loss: 0.2543 - acc: 0.9857 - val_loss: 0.8477 - val_acc: 0.7820
Epoch 61/200
1/1 - 0s - loss: 0.2226 - acc: 0.9929 - val_loss: 0.8411 - val_acc: 0.7740
Epoch 62/200
1/1 - 0s - loss: 0.2088 - acc: 0.9857 - val_loss: 0.8341 - val_acc: 0.7740
Epoch 63/200
1/1 - 0s - loss: 0.2164 - acc: 0.9929 - val_loss: 0.8272 - val_acc: 0.7780
Epoch 64/200
1/1 - 0s - loss: 0.2114 - acc: 0.9929 - val_loss: 0.8165 - val_acc: 0.7840
Epoch 65/200
1/1 - 0s - loss: 0.1887 - acc: 1.0000 - val_loss: 0.8060 - val_acc: 0.7800
Epoch 66/200
1/1 - 0s - loss: 0.1842 - acc: 0.9929 - val_loss: 0.7977 - val_acc: 0.7780
Epoch 67/200
1/1 - 0s - loss: 0.1806 - acc: 0.9857 - val_loss: 0.7880 - val_acc: 0.7780
Epoch 68/200
1/1 - 0s - loss: 0.1849 - acc: 0.9929 - val_loss: 0.7793 - val_acc: 0.7840
Epoch 69/200
1/1 - 0s - loss: 0.1462 - acc: 0.9929 - val_loss: 0.7714 - val_acc: 0.7840
Epoch 70/200
1/1 - 0s - loss: 0.1572 - acc: 0.9857 - val_loss: 0.7627 - val_acc: 0.7900
Epoch 71/200
1/1 - 0s - loss: 0.1431 - acc: 0.9857 - val_loss: 0.7563 - val_acc: 0.7880
Epoch 72/200
1/1 - 0s - loss: 0.1388 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.7880
Epoch 73/200
1/1 - 0s - loss: 0.1354 - acc: 1.0000 - val_loss: 0.7486 - val_acc: 0.7900
Epoch 74/200
1/1 - 0s - loss: 0.1260 - acc: 1.0000 - val_loss: 0.7482 - val_acc: 0.7880
Epoch 75/200
1/1 - 0s - loss: 0.1482 - acc: 0.9857 - val_loss: 0.7490 - val_acc: 0.7860
Epoch 76/200
1/1 - 0s - loss: 0.1141 - acc: 1.0000 - val_loss: 0.7527 - val_acc: 0.7820
Epoch 77/200
1/1 - 0s - loss: 0.1140 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.7760
Epoch 78/200
1/1 - 0s - loss: 0.1101 - acc: 1.0000 - val_loss: 0.7631 - val_acc: 0.7780
Epoch 79/200
1/1 - 0s - loss: 0.1228 - acc: 0.9929 - val_loss: 0.7677 - val_acc: 0.7760
Epoch 80/200
1/1 - 0s - loss: 0.0995 - acc: 0.9929 - val_loss: 0.7684 - val_acc: 0.7760
Epoch 81/200
1/1 - 0s - loss: 0.0981 - acc: 1.0000 - val_loss: 0.7640 - val_acc: 0.7820
Epoch 82/200
1/1 - 0s - loss: 0.0985 - acc: 1.0000 - val_loss: 0.7560 - val_acc: 0.7840
Epoch 83/200
1/1 - 0s - loss: 0.0978 - acc: 1.0000 - val_loss: 0.7498 - val_acc: 0.7840
Epoch 84/200
1/1 - 0s - loss: 0.0922 - acc: 1.0000 - val_loss: 0.7439 - val_acc: 0.7920
Epoch 85/200
1/1 - 0s - loss: 0.0996 - acc: 0.9929 - val_loss: 0.7388 - val_acc: 0.7940
Epoch 86/200
1/1 - 0s - loss: 0.0875 - acc: 1.0000 - val_loss: 0.7360 - val_acc: 0.7940
Epoch 87/200
1/1 - 0s - loss: 0.0789 - acc: 1.0000 - val_loss: 0.7361 - val_acc: 0.7920
Epoch 88/200
1/1 - 0s - loss: 0.0896 - acc: 1.0000 - val_loss: 0.7379 - val_acc: 0.7840
Epoch 89/200
1/1 - 0s - loss: 0.0861 - acc: 1.0000 - val_loss: 0.7397 - val_acc: 0.7840
Epoch 90/200
1/1 - 0s - loss: 0.0691 - acc: 1.0000 - val_loss: 0.7403 - val_acc: 0.7840
Epoch 91/200
1/1 - 0s - loss: 0.0724 - acc: 1.0000 - val_loss: 0.7379 - val_acc: 0.7860
Epoch 92/200
1/1 - 0s - loss: 0.0845 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.7820
Epoch 93/200
1/1 - 0s - loss: 0.0651 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.7800
Epoch 94/200
1/1 - 0s - loss: 0.0690 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.7820
Epoch 95/200
1/1 - 0s - loss: 0.0761 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.7860
Epoch 96/200
1/1 - 0s - loss: 0.0694 - acc: 1.0000 - val_loss: 0.7265 - val_acc: 0.7840
Epoch 97/200
1/1 - 0s - loss: 0.0684 - acc: 1.0000 - val_loss: 0.7235 - val_acc: 0.7880
Epoch 98/200
1/1 - 0s - loss: 0.0653 - acc: 1.0000 - val_loss: 0.7209 - val_acc: 0.7900
Epoch 99/200
1/1 - 0s - loss: 0.0749 - acc: 1.0000 - val_loss: 0.7190 - val_acc: 0.7900
Epoch 100/200
1/1 - 0s - loss: 0.0530 - acc: 1.0000 - val_loss: 0.7168 - val_acc: 0.7920
Epoch 101/200
1/1 - 0s - loss: 0.0642 - acc: 1.0000 - val_loss: 0.7176 - val_acc: 0.7920
Epoch 102/200
1/1 - 0s - loss: 0.0574 - acc: 1.0000 - val_loss: 0.7166 - val_acc: 0.7920
Epoch 103/200
1/1 - 0s - loss: 0.0692 - acc: 0.9929 - val_loss: 0.7151 - val_acc: 0.7900
Epoch 104/200
1/1 - 0s - loss: 0.0586 - acc: 0.9929 - val_loss: 0.7152 - val_acc: 0.7900
Epoch 105/200
1/1 - 0s - loss: 0.0499 - acc: 1.0000 - val_loss: 0.7160 - val_acc: 0.7920
Epoch 106/200
1/1 - 0s - loss: 0.0531 - acc: 1.0000 - val_loss: 0.7177 - val_acc: 0.7900
Epoch 107/200
1/1 - 0s - loss: 0.0543 - acc: 1.0000 - val_loss: 0.7160 - val_acc: 0.7860
Epoch 108/200
1/1 - 0s - loss: 0.0498 - acc: 1.0000 - val_loss: 0.7135 - val_acc: 0.7900
Epoch 109/200
1/1 - 0s - loss: 0.0563 - acc: 1.0000 - val_loss: 0.7156 - val_acc: 0.7880
Epoch 110/200
1/1 - 0s - loss: 0.0534 - acc: 1.0000 - val_loss: 0.7183 - val_acc: 0.7880
Epoch 111/200
1/1 - 0s - loss: 0.0481 - acc: 1.0000 - val_loss: 0.7219 - val_acc: 0.7840
Epoch 112/200
1/1 - 0s - loss: 0.0450 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.7840
Epoch 113/200
1/1 - 0s - loss: 0.0531 - acc: 1.0000 - val_loss: 0.7355 - val_acc: 0.7820
Epoch 114/200
1/1 - 0s - loss: 0.0485 - acc: 1.0000 - val_loss: 0.7422 - val_acc: 0.7840
Epoch 115/200
1/1 - 0s - loss: 0.0433 - acc: 1.0000 - val_loss: 0.7488 - val_acc: 0.7820
Epoch 116/200
1/1 - 0s - loss: 0.0446 - acc: 1.0000 - val_loss: 0.7498 - val_acc: 0.7800
Epoch 117/200
1/1 - 0s - loss: 0.0414 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.7840
Epoch 118/200
1/1 - 0s - loss: 0.0426 - acc: 1.0000 - val_loss: 0.7399 - val_acc: 0.7840
INFO:tensorflow:Assets written to: trained_models/gcn/assets
INFO:tensorflow:Assets written to: trained_models/gcn/assets
#+end_example


Log from training the improved model

#+RESULTS: imp-compile
:RESULTS:
#+begin_example
Epoch 1/1000
1/1 - 2s - loss: 1.9493 - acc: 0.1714 - val_loss: 1.9489 - val_acc: 0.1720
Epoch 2/1000
1/1 - 0s - loss: 1.9474 - acc: 0.2214 - val_loss: 1.9468 - val_acc: 0.1500
Epoch 3/1000
1/1 - 0s - loss: 1.9448 - acc: 0.3143 - val_loss: 1.9452 - val_acc: 0.4560
Epoch 4/1000
1/1 - 0s - loss: 1.9406 - acc: 0.4929 - val_loss: 1.9434 - val_acc: 0.5680
Epoch 5/1000
1/1 - 0s - loss: 1.9404 - acc: 0.4643 - val_loss: 1.9418 - val_acc: 0.6520
Epoch 6/1000
1/1 - 0s - loss: 1.9384 - acc: 0.4714 - val_loss: 1.9401 - val_acc: 0.7120
Epoch 7/1000
1/1 - 0s - loss: 1.9369 - acc: 0.5143 - val_loss: 1.9389 - val_acc: 0.6960
Epoch 8/1000
1/1 - 0s - loss: 1.9331 - acc: 0.5429 - val_loss: 1.9371 - val_acc: 0.7160
Epoch 9/1000
1/1 - 0s - loss: 1.9286 - acc: 0.6214 - val_loss: 1.9355 - val_acc: 0.7140
Epoch 10/1000
1/1 - 0s - loss: 1.9260 - acc: 0.5571 - val_loss: 1.9337 - val_acc: 0.7160
Epoch 11/1000
1/1 - 0s - loss: 1.9190 - acc: 0.5857 - val_loss: 1.9316 - val_acc: 0.7440
Epoch 12/1000
1/1 - 0s - loss: 1.9229 - acc: 0.5571 - val_loss: 1.9288 - val_acc: 0.7640
Epoch 13/1000
1/1 - 0s - loss: 1.9182 - acc: 0.6286 - val_loss: 1.9262 - val_acc: 0.7780
Epoch 14/1000
1/1 - 0s - loss: 1.9074 - acc: 0.6929 - val_loss: 1.9243 - val_acc: 0.7820
Epoch 15/1000
1/1 - 0s - loss: 1.9044 - acc: 0.6929 - val_loss: 1.9227 - val_acc: 0.7540
Epoch 16/1000
1/1 - 0s - loss: 1.8979 - acc: 0.6429 - val_loss: 1.9207 - val_acc: 0.7420
Epoch 17/1000
1/1 - 0s - loss: 1.8991 - acc: 0.6357 - val_loss: 1.9185 - val_acc: 0.7240
Epoch 18/1000
1/1 - 0s - loss: 1.8901 - acc: 0.6714 - val_loss: 1.9164 - val_acc: 0.7220
Epoch 19/1000
1/1 - 0s - loss: 1.8947 - acc: 0.6929 - val_loss: 1.9134 - val_acc: 0.7280
Epoch 20/1000
1/1 - 0s - loss: 1.8881 - acc: 0.6571 - val_loss: 1.9096 - val_acc: 0.7540
Epoch 21/1000
1/1 - 0s - loss: 1.8729 - acc: 0.7071 - val_loss: 1.9054 - val_acc: 0.7620
Epoch 22/1000
1/1 - 0s - loss: 1.8824 - acc: 0.6429 - val_loss: 1.9011 - val_acc: 0.7760
Epoch 23/1000
1/1 - 0s - loss: 1.8558 - acc: 0.7571 - val_loss: 1.8964 - val_acc: 0.7840
Epoch 24/1000
1/1 - 0s - loss: 1.8534 - acc: 0.7143 - val_loss: 1.8913 - val_acc: 0.7980
Epoch 25/1000
1/1 - 0s - loss: 1.8394 - acc: 0.7286 - val_loss: 1.8861 - val_acc: 0.7980
Epoch 26/1000
1/1 - 0s - loss: 1.8323 - acc: 0.7571 - val_loss: 1.8808 - val_acc: 0.7920
Epoch 27/1000
1/1 - 0s - loss: 1.8269 - acc: 0.7429 - val_loss: 1.8747 - val_acc: 0.7860
Epoch 28/1000
1/1 - 0s - loss: 1.8342 - acc: 0.6643 - val_loss: 1.8690 - val_acc: 0.7840
Epoch 29/1000
1/1 - 0s - loss: 1.8174 - acc: 0.7071 - val_loss: 1.8629 - val_acc: 0.7860
Epoch 30/1000
1/1 - 0s - loss: 1.7994 - acc: 0.7286 - val_loss: 1.8576 - val_acc: 0.7760
Epoch 31/1000
1/1 - 0s - loss: 1.7930 - acc: 0.7286 - val_loss: 1.8518 - val_acc: 0.7720
Epoch 32/1000
1/1 - 0s - loss: 1.7779 - acc: 0.7286 - val_loss: 1.8464 - val_acc: 0.7780
Epoch 33/1000
1/1 - 0s - loss: 1.7911 - acc: 0.6714 - val_loss: 1.8421 - val_acc: 0.7800
Epoch 34/1000
1/1 - 0s - loss: 1.7548 - acc: 0.7643 - val_loss: 1.8387 - val_acc: 0.7640
Epoch 35/1000
1/1 - 0s - loss: 1.7633 - acc: 0.7500 - val_loss: 1.8350 - val_acc: 0.7620
Epoch 36/1000
1/1 - 0s - loss: 1.7196 - acc: 0.7857 - val_loss: 1.8304 - val_acc: 0.7520
Epoch 37/1000
1/1 - 0s - loss: 1.7255 - acc: 0.7500 - val_loss: 1.8257 - val_acc: 0.7560
Epoch 38/1000
1/1 - 0s - loss: 1.6945 - acc: 0.8214 - val_loss: 1.8204 - val_acc: 0.7560
Epoch 39/1000
1/1 - 0s - loss: 1.7253 - acc: 0.7143 - val_loss: 1.8143 - val_acc: 0.7580
Epoch 40/1000
1/1 - 0s - loss: 1.7309 - acc: 0.7214 - val_loss: 1.8080 - val_acc: 0.7540
Epoch 41/1000
1/1 - 0s - loss: 1.6589 - acc: 0.7714 - val_loss: 1.8012 - val_acc: 0.7560
Epoch 42/1000
1/1 - 0s - loss: 1.6708 - acc: 0.7143 - val_loss: 1.7920 - val_acc: 0.7680
Epoch 43/1000
1/1 - 0s - loss: 1.6666 - acc: 0.7429 - val_loss: 1.7824 - val_acc: 0.7780
Epoch 44/1000
1/1 - 0s - loss: 1.6341 - acc: 0.7857 - val_loss: 1.7728 - val_acc: 0.7800
Epoch 45/1000
1/1 - 0s - loss: 1.6610 - acc: 0.7214 - val_loss: 1.7636 - val_acc: 0.7840
Epoch 46/1000
1/1 - 0s - loss: 1.5889 - acc: 0.7286 - val_loss: 1.7533 - val_acc: 0.7820
Epoch 47/1000
1/1 - 0s - loss: 1.6341 - acc: 0.7571 - val_loss: 1.7434 - val_acc: 0.7760
Epoch 48/1000
1/1 - 0s - loss: 1.6149 - acc: 0.7857 - val_loss: 1.7340 - val_acc: 0.7820
Epoch 49/1000
1/1 - 0s - loss: 1.5766 - acc: 0.7643 - val_loss: 1.7259 - val_acc: 0.7860
Epoch 50/1000
1/1 - 0s - loss: 1.5791 - acc: 0.7571 - val_loss: 1.7177 - val_acc: 0.7920
Epoch 51/1000
1/1 - 0s - loss: 1.5742 - acc: 0.7500 - val_loss: 1.7085 - val_acc: 0.7920
Epoch 52/1000
1/1 - 0s - loss: 1.5337 - acc: 0.7643 - val_loss: 1.7000 - val_acc: 0.7920
Epoch 53/1000
1/1 - 0s - loss: 1.5736 - acc: 0.7357 - val_loss: 1.6912 - val_acc: 0.7940
Epoch 54/1000
1/1 - 0s - loss: 1.5279 - acc: 0.7786 - val_loss: 1.6813 - val_acc: 0.7980
Epoch 55/1000
#+end_example
#+begin_example
1/1 - 0s - loss: 1.5736 - acc: 0.7214 - val_loss: 1.6739 - val_acc: 0.8000Epoch 56/1000
1/1 - 0s - loss: 1.4850 - acc: 0.7714 - val_loss: 1.6649 - val_acc: 0.8000
Epoch 57/1000
1/1 - 0s - loss: 1.5065 - acc: 0.7214 - val_loss: 1.6550 - val_acc: 0.8000
Epoch 58/1000
1/1 - 0s - loss: 1.4560 - acc: 0.7857 - val_loss: 1.6442 - val_acc: 0.8060
Epoch 59/1000
1/1 - 0s - loss: 1.4238 - acc: 0.8000 - val_loss: 1.6332 - val_acc: 0.8040
Epoch 60/1000
1/1 - 0s - loss: 1.4275 - acc: 0.8071 - val_loss: 1.6227 - val_acc: 0.8020
Epoch 61/1000
1/1 - 0s - loss: 1.4572 - acc: 0.7857 - val_loss: 1.6121 - val_acc: 0.7980
Epoch 62/1000
1/1 - 0s - loss: 1.4093 - acc: 0.7857 - val_loss: 1.6027 - val_acc: 0.7960
Epoch 63/1000
1/1 - 0s - loss: 1.3871 - acc: 0.8214 - val_loss: 1.5935 - val_acc: 0.8000
Epoch 64/1000
1/1 - 0s - loss: 1.4265 - acc: 0.7786 - val_loss: 1.5838 - val_acc: 0.7980
Epoch 65/1000
1/1 - 0s - loss: 1.3785 - acc: 0.8071 - val_loss: 1.5756 - val_acc: 0.7980
Epoch 66/1000
1/1 - 0s - loss: 1.3021 - acc: 0.8214 - val_loss: 1.5668 - val_acc: 0.7940
Epoch 67/1000
1/1 - 0s - loss: 1.4198 - acc: 0.7357 - val_loss: 1.5567 - val_acc: 0.7920
Epoch 68/1000
1/1 - 0s - loss: 1.3025 - acc: 0.8214 - val_loss: 1.5462 - val_acc: 0.7940
Epoch 69/1000
1/1 - 0s - loss: 1.3472 - acc: 0.7643 - val_loss: 1.5346 - val_acc: 0.7920
Epoch 70/1000
1/1 - 0s - loss: 1.3509 - acc: 0.7500 - val_loss: 1.5240 - val_acc: 0.7900
Epoch 71/1000
1/1 - 0s - loss: 1.3765 - acc: 0.7786 - val_loss: 1.5141 - val_acc: 0.7860
Epoch 72/1000
1/1 - 0s - loss: 1.4010 - acc: 0.7214 - val_loss: 1.5041 - val_acc: 0.7860
Epoch 73/1000
1/1 - 0s - loss: 1.2945 - acc: 0.8429 - val_loss: 1.4948 - val_acc: 0.7820
Epoch 74/1000
1/1 - 0s - loss: 1.3295 - acc: 0.8000 - val_loss: 1.4862 - val_acc: 0.7800
Epoch 75/1000
1/1 - 0s - loss: 1.2832 - acc: 0.7786 - val_loss: 1.4776 - val_acc: 0.7800
Epoch 76/1000
1/1 - 0s - loss: 1.2448 - acc: 0.7786 - val_loss: 1.4698 - val_acc: 0.7800
Epoch 77/1000
1/1 - 0s - loss: 1.2741 - acc: 0.8000 - val_loss: 1.4623 - val_acc: 0.7820
Epoch 78/1000
1/1 - 0s - loss: 1.3226 - acc: 0.7714 - val_loss: 1.4545 - val_acc: 0.7880
Epoch 79/1000
1/1 - 0s - loss: 1.3738 - acc: 0.7500 - val_loss: 1.4476 - val_acc: 0.7900
Epoch 80/1000
1/1 - 0s - loss: 1.1866 - acc: 0.8286 - val_loss: 1.4393 - val_acc: 0.7980
Epoch 81/1000
1/1 - 0s - loss: 1.3843 - acc: 0.7357 - val_loss: 1.4304 - val_acc: 0.8060
Epoch 82/1000
1/1 - 0s - loss: 1.2981 - acc: 0.7429 - val_loss: 1.4216 - val_acc: 0.8100
Epoch 83/1000
1/1 - 0s - loss: 1.2543 - acc: 0.7857 - val_loss: 1.4131 - val_acc: 0.8120
Epoch 84/1000
1/1 - 0s - loss: 1.2796 - acc: 0.7714 - val_loss: 1.4064 - val_acc: 0.8120
Epoch 85/1000
1/1 - 0s - loss: 1.2245 - acc: 0.7786 - val_loss: 1.3998 - val_acc: 0.8100
Epoch 86/1000
1/1 - 0s - loss: 1.2574 - acc: 0.7857 - val_loss: 1.3929 - val_acc: 0.8160
Epoch 87/1000
1/1 - 0s - loss: 1.2716 - acc: 0.8000 - val_loss: 1.3863 - val_acc: 0.8160
Epoch 88/1000
1/1 - 0s - loss: 1.1949 - acc: 0.8286 - val_loss: 1.3811 - val_acc: 0.8100
Epoch 89/1000
1/1 - 0s - loss: 1.2785 - acc: 0.7786 - val_loss: 1.3761 - val_acc: 0.8080
Epoch 90/1000
1/1 - 0s - loss: 1.1867 - acc: 0.7857 - val_loss: 1.3732 - val_acc: 0.7980
Epoch 91/1000
1/1 - 0s - loss: 1.1898 - acc: 0.7643 - val_loss: 1.3714 - val_acc: 0.7940
Epoch 92/1000
1/1 - 0s - loss: 1.1788 - acc: 0.8286 - val_loss: 1.3702 - val_acc: 0.7960
Epoch 93/1000
1/1 - 0s - loss: 1.2480 - acc: 0.7857 - val_loss: 1.3688 - val_acc: 0.7960
Epoch 94/1000
1/1 - 0s - loss: 1.1321 - acc: 0.8571 - val_loss: 1.3686 - val_acc: 0.7920
Epoch 95/1000
1/1 - 0s - loss: 1.2176 - acc: 0.7357 - val_loss: 1.3683 - val_acc: 0.7880
Epoch 96/1000
1/1 - 0s - loss: 1.1912 - acc: 0.7857 - val_loss: 1.3657 - val_acc: 0.7900
Epoch 97/1000
1/1 - 0s - loss: 1.2246 - acc: 0.7786 - val_loss: 1.3603 - val_acc: 0.7860
Epoch 98/1000
1/1 - 0s - loss: 1.1288 - acc: 0.8429 - val_loss: 1.3538 - val_acc: 0.7860
Epoch 99/1000
1/1 - 0s - loss: 1.1236 - acc: 0.8286 - val_loss: 1.3454 - val_acc: 0.7840
Epoch 100/1000
1/1 - 0s - loss: 1.1749 - acc: 0.7857 - val_loss: 1.3356 - val_acc: 0.7840
Epoch 101/1000
1/1 - 0s - loss: 1.2518 - acc: 0.7429 - val_loss: 1.3277 - val_acc: 0.7840
Epoch 102/1000
1/1 - 0s - loss: 1.0398 - acc: 0.8143 - val_loss: 1.3216 - val_acc: 0.7820
Epoch 103/1000
1/1 - 0s - loss: 1.1144 - acc: 0.8071 - val_loss: 1.3158 - val_acc: 0.7820
Epoch 104/1000
1/1 - 0s - loss: 1.2100 - acc: 0.7643 - val_loss: 1.3101 - val_acc: 0.7820
Epoch 105/1000
1/1 - 0s - loss: 1.1142 - acc: 0.8286 - val_loss: 1.3036 - val_acc: 0.7860
Epoch 106/1000
1/1 - 0s - loss: 1.1509 - acc: 0.8214 - val_loss: 1.2978 - val_acc: 0.7880
Epoch 107/1000
1/1 - 0s - loss: 1.2040 - acc: 0.8143 - val_loss: 1.2932 - val_acc: 0.7940
Epoch 108/1000
1/1 - 0s - loss: 1.2330 - acc: 0.7714 - val_loss: 1.2881 - val_acc: 0.7960
Epoch 109/1000
1/1 - 0s - loss: 1.1912 - acc: 0.7929 - val_loss: 1.2826 - val_acc: 0.7980
Epoch 110/1000
1/1 - 0s - loss: 1.1278 - acc: 0.8143 - val_loss: 1.2779 - val_acc: 0.8040
Epoch 111/1000
1/1 - 0s - loss: 1.0718 - acc: 0.8357 - val_loss: 1.2745 - val_acc: 0.8000
Epoch 112/1000
1/1 - 0s - loss: 1.1091 - acc: 0.8071 - val_loss: 1.2720 - val_acc: 0.8020
Epoch 113/1000
1/1 - 0s - loss: 1.1304 - acc: 0.8143 - val_loss: 1.2694 - val_acc: 0.8060
Epoch 114/1000
1/1 - 0s - loss: 1.1384 - acc: 0.7786 - val_loss: 1.2673 - val_acc: 0.8080
Epoch 115/1000
1/1 - 0s - loss: 1.1718 - acc: 0.7357 - val_loss: 1.2643 - val_acc: 0.8120
Epoch 116/1000
1/1 - 0s - loss: 1.1113 - acc: 0.8071 - val_loss: 1.2612 - val_acc: 0.8140
Epoch 117/1000
1/1 - 0s - loss: 1.0803 - acc: 0.7929 - val_loss: 1.2579 - val_acc: 0.8140
Epoch 118/1000
1/1 - 0s - loss: 1.1717 - acc: 0.7714 - val_loss: 1.2542 - val_acc: 0.8120
Epoch 119/1000
1/1 - 0s - loss: 1.1549 - acc: 0.7643 - val_loss: 1.2497 - val_acc: 0.8120
Epoch 120/1000
1/1 - 0s - loss: 1.0685 - acc: 0.8357 - val_loss: 1.2464 - val_acc: 0.8120
Epoch 121/1000
1/1 - 0s - loss: 0.9576 - acc: 0.8929 - val_loss: 1.2439 - val_acc: 0.8100
Epoch 122/1000
1/1 - 0s - loss: 1.1366 - acc: 0.7786 - val_loss: 1.2396 - val_acc: 0.8040
Epoch 123/1000
1/1 - 0s - loss: 1.1185 - acc: 0.8000 - val_loss: 1.2346 - val_acc: 0.8040
Epoch 124/1000
1/1 - 0s - loss: 1.0732 - acc: 0.8143 - val_loss: 1.2310 - val_acc: 0.8040
Epoch 125/1000
1/1 - 0s - loss: 1.1431 - acc: 0.7643 - val_loss: 1.2278 - val_acc: 0.8000
Epoch 126/1000
1/1 - 0s - loss: 1.0470 - acc: 0.8571 - val_loss: 1.2240 - val_acc: 0.8000
Epoch 127/1000
1/1 - 0s - loss: 1.1487 - acc: 0.7714 - val_loss: 1.2214 - val_acc: 0.8000
Epoch 128/1000
1/1 - 0s - loss: 1.1154 - acc: 0.7571 - val_loss: 1.2197 - val_acc: 0.7960
Epoch 129/1000
1/1 - 0s - loss: 1.0511 - acc: 0.8000 - val_loss: 1.2171 - val_acc: 0.7940
Epoch 130/1000
1/1 - 0s - loss: 1.1472 - acc: 0.8000 - val_loss: 1.2145 - val_acc: 0.7860
Epoch 131/1000
1/1 - 0s - loss: 1.1058 - acc: 0.8000 - val_loss: 1.2133 - val_acc: 0.7840
Epoch 132/1000
1/1 - 0s - loss: 1.0309 - acc: 0.8571 - val_loss: 1.2117 - val_acc: 0.7860
Epoch 133/1000
1/1 - 0s - loss: 1.0052 - acc: 0.8571 - val_loss: 1.2094 - val_acc: 0.7840
Epoch 134/1000
1/1 - 0s - loss: 1.0101 - acc: 0.8643 - val_loss: 1.2071 - val_acc: 0.7800
Epoch 135/1000
1/1 - 0s - loss: 1.1128 - acc: 0.7929 - val_loss: 1.2042 - val_acc: 0.7880
Epoch 136/1000
1/1 - 0s - loss: 1.0840 - acc: 0.8214 - val_loss: 1.2008 - val_acc: 0.8000
Epoch 137/1000
1/1 - 0s - loss: 1.0313 - acc: 0.8286 - val_loss: 1.1957 - val_acc: 0.8020
Epoch 138/1000
1/1 - 0s - loss: 1.0448 - acc: 0.8357 - val_loss: 1.1912 - val_acc: 0.8040
Epoch 139/1000
1/1 - 0s - loss: 1.0663 - acc: 0.8000 - val_loss: 1.1893 - val_acc: 0.8020
Epoch 140/1000
1/1 - 0s - loss: 1.0144 - acc: 0.8857 - val_loss: 1.1883 - val_acc: 0.8000
Epoch 141/1000
1/1 - 0s - loss: 1.0668 - acc: 0.8571 - val_loss: 1.1862 - val_acc: 0.8060
Epoch 142/1000
1/1 - 0s - loss: 1.0647 - acc: 0.7929 - val_loss: 1.1865 - val_acc: 0.8100
Epoch 143/1000
1/1 - 0s - loss: 1.0838 - acc: 0.8429 - val_loss: 1.1882 - val_acc: 0.8120
Epoch 144/1000
1/1 - 0s - loss: 1.1603 - acc: 0.7357 - val_loss: 1.1910 - val_acc: 0.8120
Epoch 145/1000
1/1 - 0s - loss: 1.0640 - acc: 0.8286 - val_loss: 1.1927 - val_acc: 0.8100
Epoch 146/1000
1/1 - 0s - loss: 1.0171 - acc: 0.8286 - val_loss: 1.1935 - val_acc: 0.8080
Epoch 147/1000
1/1 - 0s - loss: 1.0682 - acc: 0.8286 - val_loss: 1.1938 - val_acc: 0.8060
Epoch 148/1000
1/1 - 0s - loss: 1.1144 - acc: 0.7714 - val_loss: 1.1932 - val_acc: 0.8060
Epoch 149/1000
1/1 - 0s - loss: 1.0427 - acc: 0.8143 - val_loss: 1.1902 - val_acc: 0.8060
Epoch 150/1000
1/1 - 0s - loss: 1.0104 - acc: 0.8214 - val_loss: 1.1868 - val_acc: 0.8020
Epoch 151/1000
1/1 - 0s - loss: 0.9974 - acc: 0.8357 - val_loss: 1.1828 - val_acc: 0.8020
Epoch 152/1000
1/1 - 0s - loss: 1.0558 - acc: 0.8500 - val_loss: 1.1786 - val_acc: 0.8040
Epoch 153/1000
1/1 - 0s - loss: 1.0551 - acc: 0.7714 - val_loss: 1.1740 - val_acc: 0.8000
Epoch 154/1000
1/1 - 0s - loss: 1.0122 - acc: 0.8429 - val_loss: 1.1707 - val_acc: 0.8040
Epoch 155/1000
1/1 - 0s - loss: 0.9778 - acc: 0.8286 - val_loss: 1.1676 - val_acc: 0.8040
Epoch 156/1000
1/1 - 0s - loss: 0.9676 - acc: 0.8571 - val_loss: 1.1664 - val_acc: 0.8040
Epoch 157/1000
1/1 - 0s - loss: 0.9687 - acc: 0.8429 - val_loss: 1.1663 - val_acc: 0.8040
Epoch 158/1000
1/1 - 0s - loss: 1.0919 - acc: 0.8000 - val_loss: 1.1646 - val_acc: 0.8040
Epoch 159/1000
1/1 - 0s - loss: 1.0089 - acc: 0.8286 - val_loss: 1.1639 - val_acc: 0.8040
Epoch 160/1000
1/1 - 0s - loss: 0.9981 - acc: 0.8000 - val_loss: 1.1635 - val_acc: 0.8040
Epoch 161/1000
1/1 - 0s - loss: 1.0062 - acc: 0.8071 - val_loss: 1.1626 - val_acc: 0.8040
Epoch 162/1000
1/1 - 0s - loss: 1.0682 - acc: 0.8143 - val_loss: 1.1613 - val_acc: 0.8020
Epoch 163/1000
1/1 - 0s - loss: 0.9741 - acc: 0.8643 - val_loss: 1.1579 - val_acc: 0.8020
Epoch 164/1000
1/1 - 0s - loss: 0.9388 - acc: 0.8857 - val_loss: 1.1549 - val_acc: 0.7980
Epoch 165/1000
1/1 - 0s - loss: 1.0467 - acc: 0.8071 - val_loss: 1.1506 - val_acc: 0.7920
Epoch 166/1000
1/1 - 0s - loss: 1.0789 - acc: 0.7429 - val_loss: 1.1482 - val_acc: 0.7920
Epoch 167/1000
1/1 - 0s - loss: 1.0625 - acc: 0.8000 - val_loss: 1.1452 - val_acc: 0.7960
Epoch 168/1000
1/1 - 0s - loss: 1.0800 - acc: 0.8214 - val_loss: 1.1447 - val_acc: 0.7980
Epoch 169/1000
1/1 - 0s - loss: 1.0102 - acc: 0.8286 - val_loss: 1.1448 - val_acc: 0.7980
Epoch 170/1000
1/1 - 0s - loss: 1.0013 - acc: 0.8214 - val_loss: 1.1448 - val_acc: 0.7960
Epoch 171/1000
1/1 - 0s - loss: 1.0206 - acc: 0.7857 - val_loss: 1.1457 - val_acc: 0.7940
Epoch 172/1000
1/1 - 0s - loss: 0.9788 - acc: 0.8357 - val_loss: 1.1460 - val_acc: 0.7940
Epoch 173/1000
1/1 - 0s - loss: 1.0213 - acc: 0.8143 - val_loss: 1.1459 - val_acc: 0.7940
Epoch 174/1000
1/1 - 0s - loss: 1.0120 - acc: 0.8143 - val_loss: 1.1451 - val_acc: 0.7960
Epoch 175/1000
1/1 - 0s - loss: 0.9861 - acc: 0.8429 - val_loss: 1.1431 - val_acc: 0.7980
Epoch 176/1000
1/1 - 0s - loss: 1.1125 - acc: 0.7429 - val_loss: 1.1397 - val_acc: 0.7980
Epoch 177/1000
1/1 - 0s - loss: 1.0139 - acc: 0.8214 - val_loss: 1.1366 - val_acc: 0.7960
Epoch 178/1000
1/1 - 0s - loss: 1.0407 - acc: 0.8000 - val_loss: 1.1325 - val_acc: 0.7920
Epoch 179/1000
1/1 - 0s - loss: 0.9553 - acc: 0.8357 - val_loss: 1.1290 - val_acc: 0.7920
Epoch 180/1000
1/1 - 0s - loss: 1.0784 - acc: 0.8071 - val_loss: 1.1278 - val_acc: 0.7920
Epoch 181/1000
1/1 - 0s - loss: 1.0161 - acc: 0.8143 - val_loss: 1.1271 - val_acc: 0.7920
Epoch 182/1000
1/1 - 0s - loss: 1.0037 - acc: 0.8000 - val_loss: 1.1256 - val_acc: 0.7980
Epoch 183/1000
1/1 - 0s - loss: 1.0329 - acc: 0.8286 - val_loss: 1.1266 - val_acc: 0.7940
Epoch 184/1000
1/1 - 0s - loss: 1.0084 - acc: 0.7929 - val_loss: 1.1286 - val_acc: 0.7920
Epoch 185/1000
1/1 - 0s - loss: 0.9846 - acc: 0.8286 - val_loss: 1.1291 - val_acc: 0.7920
Epoch 186/1000
1/1 - 0s - loss: 1.0235 - acc: 0.8214 - val_loss: 1.1302 - val_acc: 0.7940
Epoch 187/1000
1/1 - 0s - loss: 0.9516 - acc: 0.8143 - val_loss: 1.1328 - val_acc: 0.7900
Epoch 188/1000
1/1 - 0s - loss: 0.9064 - acc: 0.8714 - val_loss: 1.1335 - val_acc: 0.7940
Epoch 189/1000
1/1 - 0s - loss: 0.9953 - acc: 0.8143 - val_loss: 1.1332 - val_acc: 0.7960
Epoch 190/1000
1/1 - 0s - loss: 0.8858 - acc: 0.8571 - val_loss: 1.1328 - val_acc: 0.7980
Epoch 191/1000
1/1 - 0s - loss: 0.9829 - acc: 0.8214 - val_loss: 1.1306 - val_acc: 0.7980
Epoch 192/1000
1/1 - 0s - loss: 1.0359 - acc: 0.8571 - val_loss: 1.1274 - val_acc: 0.8000
Epoch 193/1000
1/1 - 0s - loss: 1.0442 - acc: 0.8214 - val_loss: 1.1240 - val_acc: 0.8000
Epoch 194/1000
1/1 - 0s - loss: 1.0307 - acc: 0.8000 - val_loss: 1.1196 - val_acc: 0.8020
Epoch 195/1000
1/1 - 0s - loss: 0.9783 - acc: 0.8500 - val_loss: 1.1149 - val_acc: 0.8000
Epoch 196/1000
1/1 - 0s - loss: 0.9740 - acc: 0.8071 - val_loss: 1.1111 - val_acc: 0.8020
Epoch 197/1000
1/1 - 0s - loss: 1.0448 - acc: 0.7857 - val_loss: 1.1074 - val_acc: 0.8020
Epoch 198/1000
1/1 - 0s - loss: 1.0859 - acc: 0.7714 - val_loss: 1.1050 - val_acc: 0.8000
Epoch 199/1000
1/1 - 0s - loss: 0.9142 - acc: 0.8643 - val_loss: 1.1010 - val_acc: 0.8000
Epoch 200/1000
1/1 - 0s - loss: 0.9497 - acc: 0.8500 - val_loss: 1.0987 - val_acc: 0.8000
Epoch 201/1000
1/1 - 0s - loss: 1.0013 - acc: 0.8000 - val_loss: 1.0997 - val_acc: 0.7960
Epoch 202/1000
1/1 - 0s - loss: 0.9955 - acc: 0.7929 - val_loss: 1.1021 - val_acc: 0.7900
Epoch 203/1000
1/1 - 0s - loss: 0.8754 - acc: 0.8714 - val_loss: 1.1014 - val_acc: 0.7900
Epoch 204/1000
1/1 - 0s - loss: 0.9474 - acc: 0.8357 - val_loss: 1.1008 - val_acc: 0.7880
Epoch 205/1000
1/1 - 0s - loss: 0.9429 - acc: 0.8143 - val_loss: 1.1017 - val_acc: 0.7880
Epoch 206/1000
1/1 - 0s - loss: 1.0029 - acc: 0.8500 - val_loss: 1.1018 - val_acc: 0.7880
Epoch 207/1000
1/1 - 0s - loss: 0.9452 - acc: 0.8143 - val_loss: 1.1050 - val_acc: 0.7900
Epoch 208/1000
1/1 - 0s - loss: 0.9757 - acc: 0.8500 - val_loss: 1.1056 - val_acc: 0.7900
Epoch 209/1000
1/1 - 0s - loss: 1.0439 - acc: 0.7786 - val_loss: 1.1068 - val_acc: 0.7920
Epoch 210/1000
1/1 - 0s - loss: 1.0137 - acc: 0.8214 - val_loss: 1.1068 - val_acc: 0.7900
Epoch 211/1000
1/1 - 0s - loss: 0.9056 - acc: 0.8571 - val_loss: 1.1079 - val_acc: 0.7900
Epoch 212/1000
1/1 - 0s - loss: 1.0882 - acc: 0.7714 - val_loss: 1.1056 - val_acc: 0.7900
Epoch 213/1000
1/1 - 0s - loss: 1.0213 - acc: 0.7571 - val_loss: 1.1033 - val_acc: 0.7880
Epoch 214/1000
1/1 - 0s - loss: 0.9817 - acc: 0.7929 - val_loss: 1.1039 - val_acc: 0.7880
Epoch 215/1000
1/1 - 0s - loss: 0.9808 - acc: 0.8286 - val_loss: 1.1049 - val_acc: 0.7900
Epoch 216/1000
1/1 - 0s - loss: 1.0554 - acc: 0.7714 - val_loss: 1.1066 - val_acc: 0.7880
Epoch 217/1000
1/1 - 0s - loss: 1.0264 - acc: 0.8000 - val_loss: 1.1068 - val_acc: 0.7860
Epoch 218/1000
1/1 - 0s - loss: 0.8833 - acc: 0.8143 - val_loss: 1.1067 - val_acc: 0.7840
Epoch 219/1000
1/1 - 0s - loss: 0.9418 - acc: 0.8286 - val_loss: 1.1064 - val_acc: 0.7840
Epoch 220/1000
1/1 - 0s - loss: 0.9906 - acc: 0.8286 - val_loss: 1.1072 - val_acc: 0.7860
Epoch 221/1000
1/1 - 0s - loss: 0.9171 - acc: 0.8714 - val_loss: 1.1076 - val_acc: 0.7900
Epoch 222/1000
1/1 - 0s - loss: 0.9644 - acc: 0.8357 - val_loss: 1.1063 - val_acc: 0.7900
Epoch 223/1000
1/1 - 0s - loss: 1.0494 - acc: 0.7714 - val_loss: 1.1052 - val_acc: 0.7940
Epoch 224/1000
1/1 - 0s - loss: 0.9555 - acc: 0.8286 - val_loss: 1.1005 - val_acc: 0.7940
Epoch 225/1000
1/1 - 0s - loss: 0.9282 - acc: 0.8357 - val_loss: 1.0968 - val_acc: 0.8020
Epoch 226/1000
1/1 - 0s - loss: 0.8815 - acc: 0.8571 - val_loss: 1.0931 - val_acc: 0.8020
Epoch 227/1000
1/1 - 0s - loss: 1.0141 - acc: 0.8000 - val_loss: 1.0899 - val_acc: 0.8040
Epoch 228/1000
1/1 - 0s - loss: 1.0379 - acc: 0.7786 - val_loss: 1.0876 - val_acc: 0.8080
Epoch 229/1000
1/1 - 0s - loss: 0.9893 - acc: 0.8429 - val_loss: 1.0860 - val_acc: 0.8040
Epoch 230/1000
1/1 - 0s - loss: 0.9660 - acc: 0.8357 - val_loss: 1.0851 - val_acc: 0.8020
Epoch 231/1000
1/1 - 0s - loss: 0.9844 - acc: 0.7714 - val_loss: 1.0829 - val_acc: 0.8000
Epoch 232/1000
1/1 - 0s - loss: 0.9163 - acc: 0.8786 - val_loss: 1.0805 - val_acc: 0.7940
Epoch 233/1000
1/1 - 0s - loss: 1.0450 - acc: 0.8071 - val_loss: 1.0819 - val_acc: 0.7900
Epoch 234/1000
1/1 - 0s - loss: 0.9883 - acc: 0.8071 - val_loss: 1.0834 - val_acc: 0.7880
Epoch 235/1000
1/1 - 0s - loss: 1.0040 - acc: 0.8357 - val_loss: 1.0865 - val_acc: 0.7900
Epoch 236/1000
1/1 - 0s - loss: 0.9004 - acc: 0.8643 - val_loss: 1.0906 - val_acc: 0.7900
Epoch 237/1000
1/1 - 0s - loss: 1.0351 - acc: 0.8000 - val_loss: 1.0957 - val_acc: 0.7900
Epoch 238/1000
1/1 - 0s - loss: 0.8700 - acc: 0.8786 - val_loss: 1.1003 - val_acc: 0.7840
Epoch 239/1000
1/1 - 0s - loss: 0.9714 - acc: 0.8429 - val_loss: 1.1029 - val_acc: 0.7860
Epoch 240/1000
1/1 - 0s - loss: 0.9388 - acc: 0.8143 - val_loss: 1.1026 - val_acc: 0.7880
Epoch 241/1000
1/1 - 0s - loss: 0.9373 - acc: 0.8357 - val_loss: 1.1001 - val_acc: 0.7900
Epoch 242/1000
1/1 - 0s - loss: 0.9711 - acc: 0.8429 - val_loss: 1.0982 - val_acc: 0.7920
Epoch 243/1000
1/1 - 0s - loss: 1.0589 - acc: 0.7786 - val_loss: 1.0955 - val_acc: 0.7980
Epoch 244/1000
1/1 - 0s - loss: 0.9933 - acc: 0.8357 - val_loss: 1.0911 - val_acc: 0.7980
Epoch 245/1000
1/1 - 0s - loss: 0.8807 - acc: 0.8857 - val_loss: 1.0873 - val_acc: 0.8040
Epoch 246/1000
1/1 - 0s - loss: 0.9639 - acc: 0.8143 - val_loss: 1.0847 - val_acc: 0.8040
Epoch 247/1000
1/1 - 0s - loss: 1.0008 - acc: 0.8071 - val_loss: 1.0837 - val_acc: 0.8060
Epoch 248/1000
1/1 - 0s - loss: 1.0239 - acc: 0.7929 - val_loss: 1.0828 - val_acc: 0.8060
Epoch 249/1000
1/1 - 0s - loss: 1.0652 - acc: 0.7714 - val_loss: 1.0829 - val_acc: 0.8060
Epoch 250/1000
1/1 - 0s - loss: 1.0570 - acc: 0.7929 - val_loss: 1.0833 - val_acc: 0.8040
Epoch 251/1000
1/1 - 0s - loss: 0.9615 - acc: 0.8357 - val_loss: 1.0866 - val_acc: 0.8000
Epoch 252/1000
1/1 - 0s - loss: 0.8811 - acc: 0.8571 - val_loss: 1.0905 - val_acc: 0.8000
Epoch 253/1000
1/1 - 0s - loss: 0.8968 - acc: 0.8571 - val_loss: 1.0922 - val_acc: 0.8000
Epoch 254/1000
1/1 - 0s - loss: 0.9731 - acc: 0.8000 - val_loss: 1.0953 - val_acc: 0.8000
Epoch 255/1000
1/1 - 0s - loss: 1.0418 - acc: 0.8214 - val_loss: 1.0966 - val_acc: 0.7980
Epoch 256/1000
1/1 - 0s - loss: 0.9488 - acc: 0.8571 - val_loss: 1.0971 - val_acc: 0.7960
Epoch 257/1000
1/1 - 0s - loss: 0.9504 - acc: 0.8000 - val_loss: 1.1004 - val_acc: 0.7860
Epoch 258/1000
1/1 - 0s - loss: 0.9407 - acc: 0.8143 - val_loss: 1.1046 - val_acc: 0.7820
Epoch 259/1000
1/1 - 0s - loss: 0.9897 - acc: 0.8143 - val_loss: 1.1069 - val_acc: 0.7800
Epoch 260/1000
1/1 - 0s - loss: 0.9968 - acc: 0.8000 - val_loss: 1.1068 - val_acc: 0.7840
Epoch 261/1000
1/1 - 0s - loss: 1.0315 - acc: 0.8071 - val_loss: 1.1048 - val_acc: 0.7880
Epoch 262/1000
1/1 - 0s - loss: 0.9522 - acc: 0.8429 - val_loss: 1.1043 - val_acc: 0.7880
Epoch 263/1000
1/1 - 0s - loss: 1.0077 - acc: 0.7857 - val_loss: 1.1040 - val_acc: 0.7880
Epoch 264/1000
1/1 - 0s - loss: 0.8949 - acc: 0.8429 - val_loss: 1.1009 - val_acc: 0.7900
Epoch 265/1000
1/1 - 0s - loss: 0.9627 - acc: 0.8500 - val_loss: 1.0970 - val_acc: 0.7960
Epoch 266/1000
1/1 - 0s - loss: 1.0073 - acc: 0.8214 - val_loss: 1.0932 - val_acc: 0.7980
Epoch 267/1000
1/1 - 0s - loss: 0.9919 - acc: 0.8143 - val_loss: 1.0871 - val_acc: 0.7980
Epoch 268/1000
1/1 - 0s - loss: 0.9290 - acc: 0.8571 - val_loss: 1.0845 - val_acc: 0.7980
Epoch 269/1000
1/1 - 0s - loss: 1.0085 - acc: 0.7786 - val_loss: 1.0820 - val_acc: 0.8000
Epoch 270/1000
1/1 - 0s - loss: 0.8717 - acc: 0.8571 - val_loss: 1.0783 - val_acc: 0.8000
Epoch 271/1000
1/1 - 0s - loss: 0.9341 - acc: 0.8286 - val_loss: 1.0767 - val_acc: 0.8040
Epoch 272/1000
1/1 - 0s - loss: 0.9858 - acc: 0.8214 - val_loss: 1.0736 - val_acc: 0.8000
Epoch 273/1000
1/1 - 0s - loss: 1.0547 - acc: 0.8143 - val_loss: 1.0715 - val_acc: 0.7960
Epoch 274/1000
1/1 - 0s - loss: 0.8391 - acc: 0.8714 - val_loss: 1.0695 - val_acc: 0.7960
Epoch 275/1000
1/1 - 0s - loss: 0.9727 - acc: 0.8143 - val_loss: 1.0674 - val_acc: 0.7960
Epoch 276/1000
1/1 - 0s - loss: 0.9108 - acc: 0.8429 - val_loss: 1.0670 - val_acc: 0.7980
Epoch 277/1000
1/1 - 0s - loss: 0.8699 - acc: 0.8714 - val_loss: 1.0645 - val_acc: 0.7980
Epoch 278/1000
1/1 - 0s - loss: 0.9703 - acc: 0.8714 - val_loss: 1.0634 - val_acc: 0.8020
Epoch 279/1000
1/1 - 0s - loss: 0.9059 - acc: 0.8500 - val_loss: 1.0619 - val_acc: 0.8000
Epoch 280/1000
1/1 - 0s - loss: 0.9359 - acc: 0.8500 - val_loss: 1.0612 - val_acc: 0.8020
Epoch 281/1000
1/1 - 0s - loss: 0.9109 - acc: 0.8571 - val_loss: 1.0615 - val_acc: 0.8040
Epoch 282/1000
1/1 - 0s - loss: 1.0392 - acc: 0.7786 - val_loss: 1.0599 - val_acc: 0.8000
Epoch 283/1000
1/1 - 0s - loss: 0.9232 - acc: 0.8500 - val_loss: 1.0601 - val_acc: 0.7980
Epoch 284/1000
1/1 - 0s - loss: 0.8319 - acc: 0.8786 - val_loss: 1.0605 - val_acc: 0.8020
Epoch 285/1000
1/1 - 0s - loss: 0.9744 - acc: 0.8071 - val_loss: 1.0630 - val_acc: 0.8020
Epoch 286/1000
1/1 - 0s - loss: 1.0448 - acc: 0.7714 - val_loss: 1.0688 - val_acc: 0.7980
Epoch 287/1000
1/1 - 0s - loss: 0.9686 - acc: 0.8500 - val_loss: 1.0752 - val_acc: 0.7960
Epoch 288/1000
1/1 - 0s - loss: 0.9546 - acc: 0.8143 - val_loss: 1.0810 - val_acc: 0.7980
Epoch 289/1000
1/1 - 0s - loss: 0.9079 - acc: 0.8571 - val_loss: 1.0858 - val_acc: 0.7960
Epoch 290/1000
1/1 - 0s - loss: 0.8953 - acc: 0.8643 - val_loss: 1.0852 - val_acc: 0.7960
Epoch 291/1000
1/1 - 0s - loss: 0.9675 - acc: 0.8429 - val_loss: 1.0806 - val_acc: 0.7980
Epoch 292/1000
1/1 - 0s - loss: 0.9588 - acc: 0.8071 - val_loss: 1.0761 - val_acc: 0.7960
Epoch 293/1000
1/1 - 0s - loss: 1.0136 - acc: 0.8000 - val_loss: 1.0694 - val_acc: 0.8020
Epoch 294/1000
1/1 - 0s - loss: 0.9642 - acc: 0.8357 - val_loss: 1.0640 - val_acc: 0.8000
Epoch 295/1000
1/1 - 0s - loss: 0.9064 - acc: 0.8500 - val_loss: 1.0583 - val_acc: 0.8020
Epoch 296/1000
1/1 - 0s - loss: 0.9660 - acc: 0.8357 - val_loss: 1.0535 - val_acc: 0.8060
Epoch 297/1000
1/1 - 0s - loss: 0.8454 - acc: 0.8786 - val_loss: 1.0533 - val_acc: 0.8060
Epoch 298/1000
1/1 - 0s - loss: 0.9553 - acc: 0.8000 - val_loss: 1.0550 - val_acc: 0.8060
Epoch 299/1000
1/1 - 0s - loss: 0.9324 - acc: 0.8500 - val_loss: 1.0576 - val_acc: 0.8040
Epoch 300/1000
1/1 - 0s - loss: 0.8861 - acc: 0.8500 - val_loss: 1.0603 - val_acc: 0.8040
Epoch 301/1000
1/1 - 0s - loss: 1.0304 - acc: 0.8143 - val_loss: 1.0635 - val_acc: 0.8000
Epoch 302/1000
1/1 - 0s - loss: 0.9714 - acc: 0.8214 - val_loss: 1.0678 - val_acc: 0.8000
Epoch 303/1000
1/1 - 0s - loss: 1.0234 - acc: 0.7643 - val_loss: 1.0686 - val_acc: 0.8000
Epoch 304/1000
1/1 - 0s - loss: 0.8300 - acc: 0.8786 - val_loss: 1.0702 - val_acc: 0.8020
Epoch 305/1000
1/1 - 0s - loss: 0.8760 - acc: 0.8429 - val_loss: 1.0696 - val_acc: 0.8020
Epoch 306/1000
1/1 - 0s - loss: 0.9388 - acc: 0.8357 - val_loss: 1.0699 - val_acc: 0.7960
Epoch 307/1000
1/1 - 0s - loss: 0.9603 - acc: 0.8286 - val_loss: 1.0710 - val_acc: 0.8000
Epoch 308/1000
1/1 - 0s - loss: 0.9230 - acc: 0.8286 - val_loss: 1.0708 - val_acc: 0.8040
Epoch 309/1000
1/1 - 0s - loss: 1.0394 - acc: 0.7857 - val_loss: 1.0716 - val_acc: 0.8000
Epoch 310/1000
1/1 - 0s - loss: 0.9113 - acc: 0.8714 - val_loss: 1.0738 - val_acc: 0.7960
Epoch 311/1000
1/1 - 0s - loss: 0.8736 - acc: 0.8571 - val_loss: 1.0729 - val_acc: 0.8000
Epoch 312/1000
1/1 - 0s - loss: 0.9734 - acc: 0.8429 - val_loss: 1.0705 - val_acc: 0.8020
Epoch 313/1000
1/1 - 0s - loss: 0.9767 - acc: 0.8571 - val_loss: 1.0665 - val_acc: 0.8000
Epoch 314/1000
1/1 - 0s - loss: 0.9123 - acc: 0.8286 - val_loss: 1.0631 - val_acc: 0.8000
Epoch 315/1000
1/1 - 0s - loss: 0.8792 - acc: 0.8643 - val_loss: 1.0590 - val_acc: 0.8020
Epoch 316/1000
1/1 - 0s - loss: 0.9509 - acc: 0.8357 - val_loss: 1.0550 - val_acc: 0.8020
Epoch 317/1000
1/1 - 0s - loss: 0.9167 - acc: 0.8571 - val_loss: 1.0505 - val_acc: 0.8000
Epoch 318/1000
1/1 - 0s - loss: 1.0067 - acc: 0.7857 - val_loss: 1.0461 - val_acc: 0.8040
Epoch 319/1000
1/1 - 0s - loss: 0.8948 - acc: 0.8643 - val_loss: 1.0420 - val_acc: 0.8040
Epoch 320/1000
1/1 - 0s - loss: 0.8584 - acc: 0.8643 - val_loss: 1.0413 - val_acc: 0.8040
Epoch 321/1000
1/1 - 0s - loss: 0.7754 - acc: 0.9143 - val_loss: 1.0397 - val_acc: 0.8060
Epoch 322/1000
1/1 - 0s - loss: 0.8648 - acc: 0.8643 - val_loss: 1.0413 - val_acc: 0.8040
Epoch 323/1000
1/1 - 0s - loss: 0.9140 - acc: 0.8643 - val_loss: 1.0451 - val_acc: 0.8060
Epoch 324/1000
1/1 - 0s - loss: 0.9226 - acc: 0.8429 - val_loss: 1.0492 - val_acc: 0.8020
Epoch 325/1000
1/1 - 0s - loss: 0.9318 - acc: 0.8357 - val_loss: 1.0541 - val_acc: 0.8020
Epoch 326/1000
1/1 - 0s - loss: 0.9033 - acc: 0.8571 - val_loss: 1.0562 - val_acc: 0.8000
Epoch 327/1000
1/1 - 0s - loss: 0.9586 - acc: 0.8286 - val_loss: 1.0583 - val_acc: 0.7980
Epoch 328/1000
1/1 - 0s - loss: 1.0199 - acc: 0.8071 - val_loss: 1.0633 - val_acc: 0.7960
Epoch 329/1000
1/1 - 0s - loss: 0.8716 - acc: 0.8714 - val_loss: 1.0685 - val_acc: 0.8000
Epoch 330/1000
1/1 - 0s - loss: 0.8564 - acc: 0.9071 - val_loss: 1.0715 - val_acc: 0.7980
Epoch 331/1000
1/1 - 0s - loss: 0.9353 - acc: 0.8357 - val_loss: 1.0733 - val_acc: 0.8000
Epoch 332/1000
1/1 - 0s - loss: 1.0279 - acc: 0.8000 - val_loss: 1.0746 - val_acc: 0.8000
Epoch 333/1000
1/1 - 0s - loss: 1.0254 - acc: 0.8143 - val_loss: 1.0777 - val_acc: 0.8000
Epoch 334/1000
1/1 - 0s - loss: 0.8596 - acc: 0.8643 - val_loss: 1.0775 - val_acc: 0.7980
Epoch 335/1000
1/1 - 0s - loss: 0.9038 - acc: 0.8286 - val_loss: 1.0757 - val_acc: 0.7980
Epoch 336/1000
1/1 - 0s - loss: 0.9476 - acc: 0.8500 - val_loss: 1.0725 - val_acc: 0.8000
Epoch 337/1000
1/1 - 0s - loss: 0.9471 - acc: 0.8000 - val_loss: 1.0668 - val_acc: 0.8020
Epoch 338/1000
1/1 - 0s - loss: 0.9928 - acc: 0.8357 - val_loss: 1.0621 - val_acc: 0.8040
Epoch 339/1000
1/1 - 0s - loss: 0.9263 - acc: 0.8357 - val_loss: 1.0537 - val_acc: 0.8040
Epoch 340/1000
1/1 - 0s - loss: 1.0800 - acc: 0.7786 - val_loss: 1.0459 - val_acc: 0.8060
Epoch 341/1000
1/1 - 0s - loss: 0.8645 - acc: 0.8857 - val_loss: 1.0396 - val_acc: 0.8080
Epoch 342/1000
1/1 - 0s - loss: 0.9087 - acc: 0.8000 - val_loss: 1.0337 - val_acc: 0.8060
Epoch 343/1000
1/1 - 0s - loss: 0.9482 - acc: 0.8357 - val_loss: 1.0290 - val_acc: 0.8040
Epoch 344/1000
1/1 - 0s - loss: 0.9459 - acc: 0.8000 - val_loss: 1.0260 - val_acc: 0.8000
Epoch 345/1000
1/1 - 0s - loss: 0.9225 - acc: 0.8286 - val_loss: 1.0242 - val_acc: 0.7980
Epoch 346/1000
1/1 - 0s - loss: 1.0196 - acc: 0.8071 - val_loss: 1.0242 - val_acc: 0.7980
Epoch 347/1000
1/1 - 0s - loss: 1.0057 - acc: 0.7786 - val_loss: 1.0273 - val_acc: 0.8040
Epoch 348/1000
1/1 - 0s - loss: 0.9323 - acc: 0.8429 - val_loss: 1.0311 - val_acc: 0.8020
Epoch 349/1000
1/1 - 0s - loss: 0.9794 - acc: 0.8214 - val_loss: 1.0362 - val_acc: 0.8040
Epoch 350/1000
1/1 - 0s - loss: 0.8584 - acc: 0.8643 - val_loss: 1.0394 - val_acc: 0.8040
Epoch 351/1000
1/1 - 0s - loss: 0.9986 - acc: 0.8143 - val_loss: 1.0404 - val_acc: 0.8080
Epoch 352/1000
1/1 - 0s - loss: 0.9620 - acc: 0.8357 - val_loss: 1.0438 - val_acc: 0.8100
Epoch 353/1000
1/1 - 0s - loss: 0.8575 - acc: 0.8500 - val_loss: 1.0472 - val_acc: 0.8100
Epoch 354/1000
1/1 - 0s - loss: 0.8698 - acc: 0.8786 - val_loss: 1.0531 - val_acc: 0.8080
Epoch 355/1000
1/1 - 0s - loss: 0.9698 - acc: 0.8357 - val_loss: 1.0591 - val_acc: 0.8040
Epoch 356/1000
1/1 - 0s - loss: 0.9890 - acc: 0.7857 - val_loss: 1.0650 - val_acc: 0.8000
Epoch 357/1000
1/1 - 0s - loss: 0.9168 - acc: 0.8571 - val_loss: 1.0705 - val_acc: 0.7960
Epoch 358/1000
1/1 - 0s - loss: 0.9581 - acc: 0.8286 - val_loss: 1.0742 - val_acc: 0.7940
Epoch 359/1000
1/1 - 0s - loss: 0.9651 - acc: 0.8000 - val_loss: 1.0763 - val_acc: 0.7960
Epoch 360/1000
1/1 - 0s - loss: 0.8772 - acc: 0.8786 - val_loss: 1.0784 - val_acc: 0.8000
Epoch 361/1000
1/1 - 0s - loss: 0.9171 - acc: 0.8500 - val_loss: 1.0790 - val_acc: 0.8000
Epoch 362/1000
1/1 - 0s - loss: 0.9547 - acc: 0.8429 - val_loss: 1.0790 - val_acc: 0.7960
Epoch 363/1000
1/1 - 0s - loss: 0.8748 - acc: 0.8857 - val_loss: 1.0792 - val_acc: 0.7940
Epoch 364/1000
1/1 - 0s - loss: 1.0101 - acc: 0.7929 - val_loss: 1.0783 - val_acc: 0.7940
Epoch 365/1000
1/1 - 0s - loss: 0.9485 - acc: 0.8143 - val_loss: 1.0735 - val_acc: 0.7960
Epoch 366/1000
1/1 - 0s - loss: 0.9675 - acc: 0.8000 - val_loss: 1.0668 - val_acc: 0.7960
Epoch 367/1000
1/1 - 0s - loss: 0.8787 - acc: 0.8357 - val_loss: 1.0606 - val_acc: 0.8020
Epoch 368/1000
1/1 - 0s - loss: 0.8503 - acc: 0.8929 - val_loss: 1.0517 - val_acc: 0.8020
Epoch 369/1000
1/1 - 0s - loss: 0.9683 - acc: 0.8500 - val_loss: 1.0440 - val_acc: 0.8040
Epoch 370/1000
1/1 - 0s - loss: 1.0026 - acc: 0.8143 - val_loss: 1.0374 - val_acc: 0.8040
Epoch 371/1000
1/1 - 0s - loss: 0.8647 - acc: 0.8786 - val_loss: 1.0308 - val_acc: 0.8040
Epoch 372/1000
1/1 - 0s - loss: 0.9434 - acc: 0.8571 - val_loss: 1.0241 - val_acc: 0.8100
Epoch 373/1000
1/1 - 0s - loss: 1.0040 - acc: 0.8143 - val_loss: 1.0195 - val_acc: 0.8080
Epoch 374/1000
1/1 - 0s - loss: 0.9353 - acc: 0.8357 - val_loss: 1.0166 - val_acc: 0.8100
Epoch 375/1000
1/1 - 0s - loss: 0.9632 - acc: 0.8429 - val_loss: 1.0167 - val_acc: 0.8100
Epoch 376/1000
1/1 - 0s - loss: 0.9297 - acc: 0.8500 - val_loss: 1.0187 - val_acc: 0.8060
Epoch 377/1000
1/1 - 0s - loss: 1.0284 - acc: 0.8143 - val_loss: 1.0218 - val_acc: 0.8040
Epoch 378/1000
1/1 - 0s - loss: 1.0155 - acc: 0.8071 - val_loss: 1.0252 - val_acc: 0.8040
Epoch 379/1000
1/1 - 0s - loss: 0.9159 - acc: 0.8786 - val_loss: 1.0311 - val_acc: 0.8080
Epoch 380/1000
1/1 - 0s - loss: 0.9128 - acc: 0.8214 - val_loss: 1.0379 - val_acc: 0.8080
Epoch 381/1000
1/1 - 0s - loss: 0.9864 - acc: 0.8357 - val_loss: 1.0469 - val_acc: 0.8080
Epoch 382/1000
1/1 - 0s - loss: 0.9989 - acc: 0.8143 - val_loss: 1.0569 - val_acc: 0.7980
Epoch 383/1000
1/1 - 0s - loss: 0.9871 - acc: 0.8286 - val_loss: 1.0660 - val_acc: 0.7860
Epoch 384/1000
1/1 - 0s - loss: 0.9088 - acc: 0.8214 - val_loss: 1.0730 - val_acc: 0.7820
Epoch 385/1000
1/1 - 0s - loss: 1.0568 - acc: 0.7929 - val_loss: 1.0767 - val_acc: 0.7860
Epoch 386/1000
1/1 - 0s - loss: 0.9467 - acc: 0.8071 - val_loss: 1.0723 - val_acc: 0.7880
Epoch 387/1000
1/1 - 0s - loss: 0.9151 - acc: 0.8214 - val_loss: 1.0648 - val_acc: 0.7920
Epoch 388/1000
1/1 - 0s - loss: 0.9072 - acc: 0.8500 - val_loss: 1.0565 - val_acc: 0.7980
Epoch 389/1000
1/1 - 0s - loss: 1.0279 - acc: 0.7786 - val_loss: 1.0476 - val_acc: 0.8020
Epoch 390/1000
1/1 - 0s - loss: 1.0248 - acc: 0.7857 - val_loss: 1.0389 - val_acc: 0.8020
Epoch 391/1000
1/1 - 0s - loss: 0.9377 - acc: 0.8429 - val_loss: 1.0344 - val_acc: 0.8020
Epoch 392/1000
1/1 - 0s - loss: 0.8666 - acc: 0.8714 - val_loss: 1.0323 - val_acc: 0.8080
Epoch 393/1000
1/1 - 0s - loss: 0.9979 - acc: 0.8357 - val_loss: 1.0324 - val_acc: 0.8060
Epoch 394/1000
1/1 - 0s - loss: 0.8069 - acc: 0.9000 - val_loss: 1.0323 - val_acc: 0.8060
Epoch 395/1000
1/1 - 0s - loss: 0.8884 - acc: 0.8357 - val_loss: 1.0314 - val_acc: 0.8060
Epoch 396/1000
1/1 - 0s - loss: 0.9800 - acc: 0.8000 - val_loss: 1.0327 - val_acc: 0.8080
Epoch 397/1000
1/1 - 0s - loss: 0.9768 - acc: 0.7929 - val_loss: 1.0352 - val_acc: 0.8060
Epoch 398/1000
1/1 - 0s - loss: 0.9743 - acc: 0.8143 - val_loss: 1.0381 - val_acc: 0.8040
Epoch 399/1000
1/1 - 0s - loss: 0.9925 - acc: 0.8214 - val_loss: 1.0437 - val_acc: 0.8000
Epoch 400/1000
1/1 - 0s - loss: 0.9621 - acc: 0.7929 - val_loss: 1.0526 - val_acc: 0.7980
Epoch 401/1000
1/1 - 0s - loss: 1.0294 - acc: 0.8143 - val_loss: 1.0597 - val_acc: 0.7980
Epoch 402/1000
1/1 - 0s - loss: 1.0428 - acc: 0.7929 - val_loss: 1.0641 - val_acc: 0.7940
Epoch 403/1000
1/1 - 0s - loss: 0.9710 - acc: 0.8571 - val_loss: 1.0650 - val_acc: 0.7940
Epoch 404/1000
1/1 - 0s - loss: 0.9041 - acc: 0.8643 - val_loss: 1.0615 - val_acc: 0.7980
Epoch 405/1000
1/1 - 0s - loss: 0.8745 - acc: 0.8643 - val_loss: 1.0556 - val_acc: 0.7980
Epoch 406/1000
1/1 - 0s - loss: 0.7834 - acc: 0.9214 - val_loss: 1.0493 - val_acc: 0.8000
Epoch 407/1000
1/1 - 0s - loss: 0.8539 - acc: 0.8214 - val_loss: 1.0445 - val_acc: 0.8020
Epoch 408/1000
1/1 - 0s - loss: 0.9581 - acc: 0.8286 - val_loss: 1.0404 - val_acc: 0.8060
Epoch 409/1000
1/1 - 0s - loss: 0.9773 - acc: 0.8214 - val_loss: 1.0367 - val_acc: 0.8040
Epoch 410/1000
1/1 - 0s - loss: 0.8900 - acc: 0.8500 - val_loss: 1.0360 - val_acc: 0.8120
Epoch 411/1000
1/1 - 0s - loss: 0.9429 - acc: 0.8071 - val_loss: 1.0362 - val_acc: 0.8140
Epoch 412/1000
1/1 - 0s - loss: 0.9847 - acc: 0.7786 - val_loss: 1.0391 - val_acc: 0.8140
Epoch 413/1000
1/1 - 0s - loss: 0.9423 - acc: 0.7929 - val_loss: 1.0414 - val_acc: 0.8100
Epoch 414/1000
1/1 - 0s - loss: 0.8146 - acc: 0.8714 - val_loss: 1.0417 - val_acc: 0.8100
Epoch 415/1000
1/1 - 0s - loss: 0.9039 - acc: 0.8429 - val_loss: 1.0405 - val_acc: 0.8000
Epoch 416/1000
1/1 - 0s - loss: 1.0276 - acc: 0.8000 - val_loss: 1.0404 - val_acc: 0.8040
Epoch 417/1000
1/1 - 0s - loss: 1.0684 - acc: 0.7643 - val_loss: 1.0420 - val_acc: 0.8040
Epoch 418/1000
1/1 - 0s - loss: 1.0034 - acc: 0.8000 - val_loss: 1.0430 - val_acc: 0.8000
Epoch 419/1000
1/1 - 0s - loss: 0.9309 - acc: 0.8429 - val_loss: 1.0432 - val_acc: 0.7980
Epoch 420/1000
1/1 - 0s - loss: 0.9757 - acc: 0.7786 - val_loss: 1.0433 - val_acc: 0.7980
Epoch 421/1000
1/1 - 0s - loss: 0.9146 - acc: 0.8357 - val_loss: 1.0427 - val_acc: 0.8000
Epoch 422/1000
1/1 - 0s - loss: 0.8511 - acc: 0.8571 - val_loss: 1.0410 - val_acc: 0.8000
Epoch 423/1000
1/1 - 0s - loss: 0.9106 - acc: 0.8786 - val_loss: 1.0375 - val_acc: 0.7980
Epoch 424/1000
1/1 - 0s - loss: 0.9091 - acc: 0.8643 - val_loss: 1.0348 - val_acc: 0.8040
Epoch 425/1000
1/1 - 0s - loss: 0.9415 - acc: 0.8286 - val_loss: 1.0324 - val_acc: 0.8020
Epoch 426/1000
1/1 - 0s - loss: 0.9317 - acc: 0.8429 - val_loss: 1.0313 - val_acc: 0.8040
Epoch 427/1000
1/1 - 0s - loss: 0.7674 - acc: 0.9071 - val_loss: 1.0301 - val_acc: 0.8060
Epoch 428/1000
1/1 - 0s - loss: 0.9800 - acc: 0.8429 - val_loss: 1.0309 - val_acc: 0.8020
Epoch 429/1000
1/1 - 0s - loss: 0.8548 - acc: 0.8500 - val_loss: 1.0288 - val_acc: 0.8020
Epoch 430/1000
1/1 - 0s - loss: 0.7923 - acc: 0.8929 - val_loss: 1.0282 - val_acc: 0.8000
Epoch 431/1000
1/1 - 0s - loss: 0.8200 - acc: 0.8929 - val_loss: 1.0280 - val_acc: 0.7980
Epoch 432/1000
1/1 - 0s - loss: 0.8750 - acc: 0.8571 - val_loss: 1.0285 - val_acc: 0.7980
Epoch 433/1000
1/1 - 0s - loss: 0.9259 - acc: 0.8286 - val_loss: 1.0301 - val_acc: 0.7980
Epoch 434/1000
1/1 - 0s - loss: 0.8522 - acc: 0.8857 - val_loss: 1.0305 - val_acc: 0.7980
Epoch 435/1000
1/1 - 0s - loss: 0.9529 - acc: 0.8286 - val_loss: 1.0300 - val_acc: 0.8000
Epoch 436/1000
1/1 - 0s - loss: 0.9250 - acc: 0.8357 - val_loss: 1.0331 - val_acc: 0.8000
Epoch 437/1000
1/1 - 0s - loss: 0.9938 - acc: 0.7786 - val_loss: 1.0378 - val_acc: 0.7960
Epoch 438/1000
1/1 - 0s - loss: 0.8867 - acc: 0.8571 - val_loss: 1.0398 - val_acc: 0.7980
Epoch 439/1000
1/1 - 0s - loss: 0.9525 - acc: 0.8214 - val_loss: 1.0416 - val_acc: 0.8000
Epoch 440/1000
1/1 - 0s - loss: 0.9886 - acc: 0.8071 - val_loss: 1.0471 - val_acc: 0.8000
Epoch 441/1000
1/1 - 0s - loss: 0.9460 - acc: 0.8429 - val_loss: 1.0516 - val_acc: 0.7920
Epoch 442/1000
1/1 - 0s - loss: 0.9850 - acc: 0.8000 - val_loss: 1.0551 - val_acc: 0.7880
Epoch 443/1000
1/1 - 0s - loss: 0.9410 - acc: 0.8429 - val_loss: 1.0572 - val_acc: 0.7860
Epoch 444/1000
1/1 - 0s - loss: 0.8992 - acc: 0.8357 - val_loss: 1.0574 - val_acc: 0.7900
Epoch 445/1000
1/1 - 0s - loss: 0.9132 - acc: 0.8214 - val_loss: 1.0576 - val_acc: 0.7900
Epoch 446/1000
1/1 - 0s - loss: 0.9465 - acc: 0.8286 - val_loss: 1.0559 - val_acc: 0.7940
Epoch 447/1000
1/1 - 0s - loss: 0.8401 - acc: 0.8857 - val_loss: 1.0563 - val_acc: 0.7960
Epoch 448/1000
1/1 - 0s - loss: 1.0128 - acc: 0.7786 - val_loss: 1.0556 - val_acc: 0.7940
Epoch 449/1000
1/1 - 0s - loss: 1.0037 - acc: 0.7714 - val_loss: 1.0532 - val_acc: 0.7960
Epoch 450/1000
1/1 - 0s - loss: 0.9116 - acc: 0.8429 - val_loss: 1.0505 - val_acc: 0.8000
Epoch 451/1000
1/1 - 0s - loss: 0.9645 - acc: 0.8286 - val_loss: 1.0470 - val_acc: 0.7980
Epoch 452/1000
1/1 - 0s - loss: 0.8688 - acc: 0.8786 - val_loss: 1.0418 - val_acc: 0.8000
Epoch 453/1000
1/1 - 0s - loss: 0.9768 - acc: 0.8214 - val_loss: 1.0354 - val_acc: 0.8000
Epoch 454/1000
1/1 - 0s - loss: 0.8692 - acc: 0.8429 - val_loss: 1.0284 - val_acc: 0.8060
Epoch 455/1000
1/1 - 0s - loss: 0.8566 - acc: 0.8857 - val_loss: 1.0241 - val_acc: 0.8120
Epoch 456/1000
1/1 - 0s - loss: 0.9035 - acc: 0.8214 - val_loss: 1.0250 - val_acc: 0.8100
Epoch 457/1000
1/1 - 0s - loss: 0.8821 - acc: 0.8286 - val_loss: 1.0283 - val_acc: 0.8080
Epoch 458/1000
1/1 - 0s - loss: 0.8829 - acc: 0.8500 - val_loss: 1.0339 - val_acc: 0.8100
Epoch 459/1000
1/1 - 0s - loss: 0.9242 - acc: 0.7929 - val_loss: 1.0399 - val_acc: 0.8100
Epoch 460/1000
1/1 - 0s - loss: 0.9888 - acc: 0.7786 - val_loss: 1.0416 - val_acc: 0.8080
Epoch 461/1000
1/1 - 0s - loss: 0.9885 - acc: 0.8286 - val_loss: 1.0414 - val_acc: 0.8060
Epoch 462/1000
1/1 - 0s - loss: 0.9583 - acc: 0.8071 - val_loss: 1.0407 - val_acc: 0.8040
Epoch 463/1000
1/1 - 0s - loss: 0.9684 - acc: 0.8214 - val_loss: 1.0416 - val_acc: 0.8000
Epoch 464/1000
1/1 - 0s - loss: 0.9477 - acc: 0.8429 - val_loss: 1.0461 - val_acc: 0.7960
Epoch 465/1000
1/1 - 0s - loss: 0.9538 - acc: 0.8214 - val_loss: 1.0508 - val_acc: 0.7960
Epoch 466/1000
1/1 - 0s - loss: 0.8947 - acc: 0.8500 - val_loss: 1.0573 - val_acc: 0.7960
Epoch 467/1000
1/1 - 0s - loss: 0.9071 - acc: 0.8643 - val_loss: 1.0624 - val_acc: 0.7900
Epoch 468/1000
1/1 - 0s - loss: 0.9178 - acc: 0.8429 - val_loss: 1.0642 - val_acc: 0.7920
Epoch 469/1000
1/1 - 0s - loss: 0.8648 - acc: 0.8429 - val_loss: 1.0654 - val_acc: 0.7900
Epoch 470/1000
1/1 - 0s - loss: 0.8912 - acc: 0.8286 - val_loss: 1.0640 - val_acc: 0.7900
Epoch 471/1000
1/1 - 0s - loss: 0.9256 - acc: 0.8000 - val_loss: 1.0604 - val_acc: 0.7920
Epoch 472/1000
1/1 - 0s - loss: 1.0183 - acc: 0.7643 - val_loss: 1.0573 - val_acc: 0.7960
Epoch 473/1000
1/1 - 0s - loss: 0.9227 - acc: 0.8000 - val_loss: 1.0513 - val_acc: 0.7980
Epoch 474/1000
1/1 - 0s - loss: 0.9451 - acc: 0.8000 - val_loss: 1.0470 - val_acc: 0.7980
WARNING:absl:Found untraced functions such as dropout_layer_call_and_return_conditional_losses, dropout_layer_call_fn, dropout_1_layer_call_and_return_conditional_losses, dropout_1_layer_call_fn, dropout_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.
WARNING:absl:Found untraced functions such as dropout_layer_call_and_return_conditional_losses, dropout_layer_call_fn, dropout_1_layer_call_and_return_conditional_losses, dropout_1_layer_call_fn, dropout_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: trained_models/improved/assets
INFO:tensorflow:Assets written to: trained_models/improved/assets
#+end_example
:END:
